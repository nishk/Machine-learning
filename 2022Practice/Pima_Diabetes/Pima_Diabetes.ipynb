{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Pima Indians Diabetes Database Analysis\n",
    "#The datasets consist of several medical predictor (independent) variables and one target (dependent) variable, Outcome. Independent variables include the number of pregnancies the patient has had, their BMI, insulin level, age, and so on\n",
    "#Source - https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import seaborn as sns\n",
    "\n",
    "dataset = '/Users/1flo/Downloads/Machine-learning/2022Practice/Pima_Diabetes/diabetes.csv'\n",
    "df = pd.read_csv(dataset)\n",
    "dfh = df.head()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(' Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.iloc[:, 0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df.iloc[:,[8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Define and setup the dataset using pytorch inbuilt functions\n",
    "# train_data = torch.from_numpy(np.asarray(train_data))\n",
    "# test_data = torch.from_numpy(np.asarray(test_data))\n",
    "# train_ds = TensorDataset(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and setup the dataset using pytorch inbuilt functions\n",
    "train_data = torch.tensor(np.asarray(train_data),dtype=torch.float32)\n",
    "test_data = torch.tensor(np.asarray(test_data),dtype=torch.float32)\n",
    "train_ds = TensorDataset(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dtype)\n",
    "print(test_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  6.0000, 148.0000,  72.0000,  35.0000,   0.0000,  33.6000,   0.6270,\n",
       "           50.0000],\n",
       "         [  1.0000,  85.0000,  66.0000,  29.0000,   0.0000,  26.6000,   0.3510,\n",
       "           31.0000],\n",
       "         [  8.0000, 183.0000,  64.0000,   0.0000,   0.0000,  23.3000,   0.6720,\n",
       "           32.0000]]),\n",
       " tensor([[1.],\n",
       "         [0.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1000e+01, 1.4300e+02, 9.4000e+01, 3.3000e+01, 1.4600e+02, 3.6600e+01,\n",
      "         2.5400e-01, 5.1000e+01],\n",
      "        [1.0000e+00, 1.2200e+02, 6.4000e+01, 3.2000e+01, 1.5600e+02, 3.5100e+01,\n",
      "         6.9200e-01, 3.0000e+01],\n",
      "        [4.0000e+00, 1.4500e+02, 8.2000e+01, 1.8000e+01, 0.0000e+00, 3.2500e+01,\n",
      "         2.3500e-01, 7.0000e+01],\n",
      "        [1.0000e+00, 1.7200e+02, 6.8000e+01, 4.9000e+01, 5.7900e+02, 4.2400e+01,\n",
      "         7.0200e-01, 2.8000e+01],\n",
      "        [1.0000e+00, 1.2100e+02, 7.8000e+01, 3.9000e+01, 7.4000e+01, 3.9000e+01,\n",
      "         2.6100e-01, 2.8000e+01]])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "#Define and setup the DataLoader\n",
    "\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "for xi,yi in train_dl:\n",
    "    print(xi)\n",
    "    print(yi)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2791, -0.0461, -0.1751,  0.3528, -0.2665,  0.3515, -0.1052, -0.1370]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0139], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2791, -0.0461, -0.1751,  0.3528, -0.2665,  0.3515, -0.1052, -0.1370]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0139], requires_grad=True)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the model for weights and bias using in-built nn.Linear which does ot automatically\n",
    "\n",
    "# class NeuralNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NeuralNetwork, self).__init__() #Gotta understand this command\n",
    "#         self.linear1 = torch.nn.Linear(8,32)\n",
    "#         self.linear2 = torch.nn.Linear(32,1)\n",
    "    \n",
    "#     model = nn.Sequential(self.linear1)\n",
    "\n",
    "model = nn.Linear(8,1)\n",
    "print(model.weight)\n",
    "print(model.bias)\n",
    "\n",
    "#Parameters\n",
    "list(model.parameters())\n",
    "\n",
    "#preds = model(train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1566.1562, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Define Loss Function\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "loss_fn = F.mse_loss\n",
    "\n",
    "loss = loss_fn(model(train_data), test_data)\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Optimizer/Algorithm - SGD (GD) & Train the model\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "def Fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        if (epoch+1) % 10 ==0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 1.1036\n",
      "Epoch [20/200], Loss: 0.6940\n",
      "Epoch [30/200], Loss: 0.2789\n",
      "Epoch [40/200], Loss: 0.1297\n",
      "Epoch [50/200], Loss: 0.1546\n",
      "Epoch [60/200], Loss: 0.4523\n",
      "Epoch [70/200], Loss: 0.3640\n",
      "Epoch [80/200], Loss: 0.2437\n",
      "Epoch [90/200], Loss: 0.2126\n",
      "Epoch [100/200], Loss: 0.0612\n",
      "Epoch [110/200], Loss: 0.0886\n",
      "Epoch [120/200], Loss: 0.4168\n",
      "Epoch [130/200], Loss: 0.1982\n",
      "Epoch [140/200], Loss: 0.2240\n",
      "Epoch [150/200], Loss: 0.1109\n",
      "Epoch [160/200], Loss: 0.2375\n",
      "Epoch [170/200], Loss: 0.2604\n",
      "Epoch [180/200], Loss: 0.1780\n",
      "Epoch [190/200], Loss: 0.2599\n",
      "Epoch [200/200], Loss: 0.5355\n"
     ]
    }
   ],
   "source": [
    "Fit(200, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets are tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "predictions are tensor([[ 0.6580],\n",
      "        [ 0.2714],\n",
      "        [ 0.8083],\n",
      "        [ 0.4113],\n",
      "        [ 0.6893],\n",
      "        [ 0.4528],\n",
      "        [ 0.4767],\n",
      "        [ 0.9223],\n",
      "        [ 1.4149],\n",
      "        [ 0.3131],\n",
      "        [ 0.3991],\n",
      "        [ 0.8353],\n",
      "        [ 0.5251],\n",
      "        [ 1.6760],\n",
      "        [ 0.8525],\n",
      "        [ 0.7268],\n",
      "        [ 0.6733],\n",
      "        [ 0.4700],\n",
      "        [ 0.7105],\n",
      "        [ 0.5240],\n",
      "        [ 0.7046],\n",
      "        [ 0.4311],\n",
      "        [ 0.8549],\n",
      "        [ 0.5614],\n",
      "        [ 0.8504],\n",
      "        [ 0.7830],\n",
      "        [ 0.7025],\n",
      "        [ 0.4322],\n",
      "        [ 0.8215],\n",
      "        [ 0.4175],\n",
      "        [ 0.4590],\n",
      "        [ 0.8517],\n",
      "        [ 0.4024],\n",
      "        [ 0.2555],\n",
      "        [ 0.5687],\n",
      "        [ 0.5715],\n",
      "        [ 0.6920],\n",
      "        [ 0.4836],\n",
      "        [ 0.3679],\n",
      "        [ 0.6171],\n",
      "        [ 0.8825],\n",
      "        [ 0.5668],\n",
      "        [ 0.3638],\n",
      "        [ 0.9702],\n",
      "        [ 0.7359],\n",
      "        [ 0.6386],\n",
      "        [ 0.5736],\n",
      "        [ 0.1949],\n",
      "        [ 0.5527],\n",
      "        [ 0.5954],\n",
      "        [ 0.3157],\n",
      "        [ 0.4103],\n",
      "        [ 0.3745],\n",
      "        [ 1.0832],\n",
      "        [ 1.0743],\n",
      "        [ 0.2594],\n",
      "        [ 1.2576],\n",
      "        [ 0.4224],\n",
      "        [ 0.3886],\n",
      "        [ 0.6123],\n",
      "        [ 0.3955],\n",
      "        [ 0.6364],\n",
      "        [ 0.1282],\n",
      "        [ 0.6827],\n",
      "        [ 0.5533],\n",
      "        [ 0.4117],\n",
      "        [ 0.2560],\n",
      "        [ 0.3185],\n",
      "        [ 0.3084],\n",
      "        [ 0.6690],\n",
      "        [ 0.4364],\n",
      "        [ 0.7693],\n",
      "        [ 0.6615],\n",
      "        [ 0.7913],\n",
      "        [ 0.2338],\n",
      "        [-0.0438],\n",
      "        [ 0.2481],\n",
      "        [ 0.4398],\n",
      "        [ 0.8234],\n",
      "        [ 0.4078],\n",
      "        [ 0.5200],\n",
      "        [ 0.3685],\n",
      "        [ 0.3829],\n",
      "        [ 0.3285],\n",
      "        [ 0.5384],\n",
      "        [ 0.5057],\n",
      "        [ 0.6808],\n",
      "        [ 0.4961],\n",
      "        [ 0.9750],\n",
      "        [ 0.3759],\n",
      "        [ 0.2407],\n",
      "        [ 0.6478],\n",
      "        [ 0.5074],\n",
      "        [ 0.5049],\n",
      "        [ 0.4992],\n",
      "        [ 0.9111],\n",
      "        [ 0.3908],\n",
      "        [ 0.3214],\n",
      "        [ 0.5579],\n",
      "        [ 0.7237],\n",
      "        [ 0.5755],\n",
      "        [ 0.5968],\n",
      "        [ 0.2766],\n",
      "        [ 0.2691],\n",
      "        [ 0.2954],\n",
      "        [ 0.6320],\n",
      "        [ 0.0585],\n",
      "        [ 0.8087],\n",
      "        [ 0.4029],\n",
      "        [ 0.3253],\n",
      "        [ 0.8840],\n",
      "        [ 1.2969],\n",
      "        [ 0.3326],\n",
      "        [ 0.3271],\n",
      "        [ 0.9774],\n",
      "        [ 0.4942],\n",
      "        [ 0.5359],\n",
      "        [ 0.3884],\n",
      "        [ 0.4105],\n",
      "        [ 0.3934],\n",
      "        [ 0.8033],\n",
      "        [ 0.5627],\n",
      "        [ 0.5016],\n",
      "        [ 0.5083],\n",
      "        [ 0.3649],\n",
      "        [ 0.6979],\n",
      "        [ 0.6843],\n",
      "        [ 0.6088],\n",
      "        [ 0.5164],\n",
      "        [ 0.2169],\n",
      "        [ 0.9070],\n",
      "        [ 0.5942],\n",
      "        [ 1.0014],\n",
      "        [ 0.4352],\n",
      "        [ 0.3152],\n",
      "        [ 0.7098],\n",
      "        [ 0.3551],\n",
      "        [ 0.4019],\n",
      "        [ 0.3692],\n",
      "        [ 0.8399],\n",
      "        [ 0.4171],\n",
      "        [ 0.4648],\n",
      "        [ 0.5587],\n",
      "        [ 0.5835],\n",
      "        [ 1.0159],\n",
      "        [ 0.1145],\n",
      "        [ 0.3126],\n",
      "        [ 0.4480],\n",
      "        [ 0.6229],\n",
      "        [ 0.3203],\n",
      "        [ 0.7606],\n",
      "        [ 0.4168],\n",
      "        [ 0.8064],\n",
      "        [ 1.0859],\n",
      "        [ 0.9651],\n",
      "        [ 0.7592],\n",
      "        [ 0.4659],\n",
      "        [ 0.5066],\n",
      "        [ 0.3472],\n",
      "        [ 1.1011],\n",
      "        [ 0.5680],\n",
      "        [ 0.6321],\n",
      "        [ 0.7481],\n",
      "        [ 0.3825],\n",
      "        [ 0.3433],\n",
      "        [ 0.5677],\n",
      "        [ 0.6454],\n",
      "        [ 0.4498],\n",
      "        [ 0.4481],\n",
      "        [ 0.3995],\n",
      "        [ 0.4066],\n",
      "        [ 0.7491],\n",
      "        [ 0.5458],\n",
      "        [ 0.3939],\n",
      "        [ 0.3241],\n",
      "        [ 0.9707],\n",
      "        [ 0.3270],\n",
      "        [ 0.6549],\n",
      "        [ 0.6729],\n",
      "        [ 0.4888],\n",
      "        [ 0.3112],\n",
      "        [ 0.5179],\n",
      "        [-0.1263],\n",
      "        [ 0.3125],\n",
      "        [ 0.5550],\n",
      "        [ 0.9061],\n",
      "        [ 1.3692],\n",
      "        [ 0.3438],\n",
      "        [ 0.5909],\n",
      "        [ 0.7455],\n",
      "        [ 0.4276],\n",
      "        [ 0.7388],\n",
      "        [ 0.7364],\n",
      "        [ 1.0899],\n",
      "        [ 0.4626],\n",
      "        [ 0.9147],\n",
      "        [ 0.3808],\n",
      "        [ 0.4183],\n",
      "        [ 0.5609],\n",
      "        [ 1.0265],\n",
      "        [ 0.2888],\n",
      "        [ 0.5192],\n",
      "        [ 0.3050],\n",
      "        [ 0.3532],\n",
      "        [ 0.6990],\n",
      "        [ 0.4277],\n",
      "        [ 1.2187],\n",
      "        [ 0.6139],\n",
      "        [ 0.4650],\n",
      "        [ 0.8315],\n",
      "        [ 0.3062],\n",
      "        [ 0.5672],\n",
      "        [ 0.7709],\n",
      "        [ 0.7289],\n",
      "        [ 0.7319],\n",
      "        [ 1.1278],\n",
      "        [ 0.6626],\n",
      "        [ 0.6864],\n",
      "        [ 0.2452],\n",
      "        [ 0.5314],\n",
      "        [ 1.1809],\n",
      "        [ 0.4936],\n",
      "        [ 0.8136],\n",
      "        [ 0.8649],\n",
      "        [ 0.3428],\n",
      "        [ 0.3332],\n",
      "        [ 0.3306],\n",
      "        [ 0.7665],\n",
      "        [ 1.4905],\n",
      "        [ 0.5301],\n",
      "        [ 0.5660],\n",
      "        [ 1.0590],\n",
      "        [ 0.1924],\n",
      "        [ 0.5206],\n",
      "        [ 0.3235],\n",
      "        [ 0.7724],\n",
      "        [ 0.9903],\n",
      "        [ 0.6538],\n",
      "        [ 0.6993],\n",
      "        [ 0.2082],\n",
      "        [ 0.3349],\n",
      "        [ 0.4672],\n",
      "        [ 0.5830],\n",
      "        [ 0.6882],\n",
      "        [ 0.8094],\n",
      "        [ 0.7416],\n",
      "        [ 0.6345],\n",
      "        [ 1.3781],\n",
      "        [ 1.0813],\n",
      "        [ 0.3421],\n",
      "        [ 0.5949],\n",
      "        [ 0.4156],\n",
      "        [ 0.3016],\n",
      "        [ 0.3132],\n",
      "        [ 0.7519],\n",
      "        [ 0.4360],\n",
      "        [ 0.4821],\n",
      "        [ 0.4506],\n",
      "        [ 1.1905],\n",
      "        [ 0.8574],\n",
      "        [ 0.9519],\n",
      "        [ 0.8084],\n",
      "        [ 0.3716],\n",
      "        [ 0.5549],\n",
      "        [ 0.5489],\n",
      "        [ 0.4114],\n",
      "        [ 0.7525],\n",
      "        [ 0.5138],\n",
      "        [ 0.3865],\n",
      "        [ 0.8467],\n",
      "        [ 0.4857],\n",
      "        [ 0.4901],\n",
      "        [ 0.4023],\n",
      "        [ 0.2496],\n",
      "        [ 0.6310],\n",
      "        [ 0.4691],\n",
      "        [ 0.5186],\n",
      "        [ 0.4623],\n",
      "        [ 0.3859],\n",
      "        [ 0.6359],\n",
      "        [ 0.5638],\n",
      "        [ 0.8057],\n",
      "        [ 0.7199],\n",
      "        [ 0.6826],\n",
      "        [ 0.3303],\n",
      "        [ 0.7044],\n",
      "        [ 1.2284],\n",
      "        [ 0.6483],\n",
      "        [ 0.4370],\n",
      "        [ 0.5864],\n",
      "        [ 0.2201],\n",
      "        [ 0.4666],\n",
      "        [ 0.6495],\n",
      "        [ 0.8154],\n",
      "        [ 0.6309],\n",
      "        [ 0.8426],\n",
      "        [ 0.9513],\n",
      "        [ 0.5989],\n",
      "        [ 0.7990],\n",
      "        [ 0.4299],\n",
      "        [ 0.8728],\n",
      "        [ 0.7655],\n",
      "        [ 0.3733],\n",
      "        [ 0.5039],\n",
      "        [ 0.5336],\n",
      "        [ 0.6165],\n",
      "        [ 0.9300],\n",
      "        [ 0.6388],\n",
      "        [ 0.5465],\n",
      "        [ 0.6646],\n",
      "        [ 0.3525],\n",
      "        [ 0.5418],\n",
      "        [ 0.6679],\n",
      "        [ 0.5758],\n",
      "        [ 0.4270],\n",
      "        [ 0.5494],\n",
      "        [ 0.3383],\n",
      "        [ 0.7321],\n",
      "        [ 0.6908],\n",
      "        [ 0.8117],\n",
      "        [ 0.7810],\n",
      "        [ 0.4488],\n",
      "        [ 0.4225],\n",
      "        [ 0.7255],\n",
      "        [ 0.4539],\n",
      "        [ 0.7675],\n",
      "        [ 0.6331],\n",
      "        [ 0.9186],\n",
      "        [ 0.5484],\n",
      "        [ 0.5694],\n",
      "        [ 0.4073],\n",
      "        [ 0.4334],\n",
      "        [ 1.0698],\n",
      "        [ 0.5191],\n",
      "        [ 0.3899],\n",
      "        [ 0.9885],\n",
      "        [ 0.6399],\n",
      "        [ 0.4576],\n",
      "        [ 0.8705],\n",
      "        [ 0.8086],\n",
      "        [ 0.5473],\n",
      "        [ 0.3202],\n",
      "        [-0.0991],\n",
      "        [ 0.4740],\n",
      "        [ 0.4610],\n",
      "        [ 0.6991],\n",
      "        [ 0.6689],\n",
      "        [ 0.7105],\n",
      "        [ 0.4445],\n",
      "        [-0.0141],\n",
      "        [ 0.3878],\n",
      "        [ 0.5151],\n",
      "        [ 0.1881],\n",
      "        [ 0.3265],\n",
      "        [ 0.3386],\n",
      "        [ 0.7206],\n",
      "        [ 0.6863],\n",
      "        [ 1.0532],\n",
      "        [ 0.5886],\n",
      "        [ 1.0168],\n",
      "        [ 1.1920],\n",
      "        [ 0.6861],\n",
      "        [ 0.3421],\n",
      "        [ 0.5961],\n",
      "        [ 0.9361],\n",
      "        [ 0.5833],\n",
      "        [ 0.5143],\n",
      "        [ 0.3031],\n",
      "        [ 0.2807],\n",
      "        [ 0.5359],\n",
      "        [ 1.0507],\n",
      "        [ 0.2165],\n",
      "        [ 0.3537],\n",
      "        [ 0.5844],\n",
      "        [ 0.7079],\n",
      "        [ 1.0900],\n",
      "        [ 0.3202],\n",
      "        [ 0.4360],\n",
      "        [ 0.7402],\n",
      "        [ 0.2601],\n",
      "        [ 0.4143],\n",
      "        [ 0.3041],\n",
      "        [ 0.5205],\n",
      "        [ 0.2691],\n",
      "        [ 0.5517],\n",
      "        [ 0.5104],\n",
      "        [ 0.4667],\n",
      "        [ 0.4767],\n",
      "        [ 0.8771],\n",
      "        [ 0.4259],\n",
      "        [ 0.5680],\n",
      "        [ 0.7785],\n",
      "        [ 0.8982],\n",
      "        [ 0.4944],\n",
      "        [ 0.5942],\n",
      "        [ 0.6916],\n",
      "        [ 0.4610],\n",
      "        [ 0.5313],\n",
      "        [ 0.2271],\n",
      "        [ 0.8565],\n",
      "        [ 0.4172],\n",
      "        [ 0.6205],\n",
      "        [ 0.6697],\n",
      "        [ 0.3578],\n",
      "        [ 0.7834],\n",
      "        [ 0.7915],\n",
      "        [ 0.4373],\n",
      "        [ 0.2967],\n",
      "        [ 0.7960],\n",
      "        [ 1.3445],\n",
      "        [ 0.3809],\n",
      "        [ 0.5849],\n",
      "        [ 0.8076],\n",
      "        [ 0.5735],\n",
      "        [ 0.7298],\n",
      "        [ 1.2069],\n",
      "        [ 0.2456],\n",
      "        [ 0.5904],\n",
      "        [ 0.1596],\n",
      "        [ 0.6572],\n",
      "        [ 0.6163],\n",
      "        [ 0.3744],\n",
      "        [ 0.4985],\n",
      "        [ 0.4525],\n",
      "        [ 0.9709],\n",
      "        [ 1.1074],\n",
      "        [ 0.4052],\n",
      "        [ 0.9593],\n",
      "        [ 0.6166],\n",
      "        [ 0.4960],\n",
      "        [ 0.6113],\n",
      "        [ 0.3801],\n",
      "        [ 0.2685],\n",
      "        [ 0.4969],\n",
      "        [ 0.1838],\n",
      "        [ 0.8713],\n",
      "        [ 0.7476],\n",
      "        [ 0.5947],\n",
      "        [ 0.2727],\n",
      "        [ 0.3868],\n",
      "        [ 0.6072],\n",
      "        [ 0.3496],\n",
      "        [ 0.6642],\n",
      "        [ 0.4495],\n",
      "        [ 0.5016],\n",
      "        [ 0.6689],\n",
      "        [ 0.3408],\n",
      "        [ 0.4053],\n",
      "        [ 0.4453],\n",
      "        [ 0.4673],\n",
      "        [ 0.3178],\n",
      "        [ 0.4778],\n",
      "        [ 0.5664],\n",
      "        [ 0.6170],\n",
      "        [ 0.5716],\n",
      "        [ 1.0265],\n",
      "        [ 0.5002],\n",
      "        [ 0.4435],\n",
      "        [ 0.9345],\n",
      "        [ 0.6782],\n",
      "        [ 0.5561],\n",
      "        [ 0.1698],\n",
      "        [ 0.4220],\n",
      "        [ 0.3325],\n",
      "        [ 0.3622],\n",
      "        [ 0.5359],\n",
      "        [ 0.2983],\n",
      "        [ 0.4595],\n",
      "        [ 0.8688],\n",
      "        [ 0.8900],\n",
      "        [ 0.5456],\n",
      "        [ 0.5372],\n",
      "        [ 0.4865],\n",
      "        [ 0.5426],\n",
      "        [ 0.4912],\n",
      "        [ 0.4296],\n",
      "        [ 0.5437],\n",
      "        [ 0.5674],\n",
      "        [ 0.6705],\n",
      "        [ 0.4687],\n",
      "        [ 1.0305],\n",
      "        [ 0.4050],\n",
      "        [ 0.4245],\n",
      "        [ 0.3902],\n",
      "        [ 0.8592],\n",
      "        [ 0.8346],\n",
      "        [ 1.1138],\n",
      "        [ 0.9239],\n",
      "        [ 0.3646],\n",
      "        [ 0.8184],\n",
      "        [ 0.3876],\n",
      "        [ 0.2557],\n",
      "        [ 0.4511],\n",
      "        [ 0.5585],\n",
      "        [ 0.4100],\n",
      "        [ 0.6992],\n",
      "        [ 0.4436],\n",
      "        [ 0.3200],\n",
      "        [ 1.0511],\n",
      "        [ 0.8333],\n",
      "        [ 0.4038],\n",
      "        [ 0.3540],\n",
      "        [ 0.0145],\n",
      "        [ 0.5257],\n",
      "        [ 0.3921],\n",
      "        [ 0.3698],\n",
      "        [ 0.7436],\n",
      "        [ 0.6585],\n",
      "        [ 0.3928],\n",
      "        [ 0.4911],\n",
      "        [ 0.4914],\n",
      "        [ 0.7185],\n",
      "        [ 0.4348],\n",
      "        [ 0.3044],\n",
      "        [ 0.5245],\n",
      "        [ 0.7969],\n",
      "        [ 0.7783],\n",
      "        [ 0.5434],\n",
      "        [ 0.5330],\n",
      "        [ 0.7408],\n",
      "        [ 0.2746],\n",
      "        [ 0.6165],\n",
      "        [ 0.6276],\n",
      "        [ 0.6218],\n",
      "        [ 0.5598],\n",
      "        [ 0.3033],\n",
      "        [ 0.3719],\n",
      "        [ 0.5455],\n",
      "        [ 0.6087],\n",
      "        [ 0.3145],\n",
      "        [ 0.5759],\n",
      "        [ 0.3667],\n",
      "        [ 0.3901],\n",
      "        [ 0.6618],\n",
      "        [ 0.2878],\n",
      "        [ 0.8482],\n",
      "        [ 0.2547],\n",
      "        [ 0.0593],\n",
      "        [ 0.6254],\n",
      "        [ 0.5811],\n",
      "        [ 0.7275],\n",
      "        [ 0.6978],\n",
      "        [ 0.4030],\n",
      "        [ 0.3756],\n",
      "        [ 0.3447],\n",
      "        [ 1.0615],\n",
      "        [ 1.0313],\n",
      "        [ 0.7625],\n",
      "        [ 0.6864],\n",
      "        [ 0.6118],\n",
      "        [ 0.4170],\n",
      "        [ 0.4190],\n",
      "        [ 0.4119],\n",
      "        [ 0.3573],\n",
      "        [ 0.4394],\n",
      "        [ 0.7987],\n",
      "        [ 0.3968],\n",
      "        [ 0.4860],\n",
      "        [ 0.6932],\n",
      "        [ 0.4484],\n",
      "        [ 0.5603],\n",
      "        [ 1.1343],\n",
      "        [ 0.4152],\n",
      "        [ 0.5016],\n",
      "        [ 0.2098],\n",
      "        [ 0.4299],\n",
      "        [ 0.3944],\n",
      "        [ 0.6134],\n",
      "        [ 0.7880],\n",
      "        [ 0.6499],\n",
      "        [ 0.2847],\n",
      "        [ 0.3409],\n",
      "        [ 0.5235],\n",
      "        [ 0.5566],\n",
      "        [ 0.7720],\n",
      "        [ 0.6577],\n",
      "        [ 0.6433],\n",
      "        [ 0.4278],\n",
      "        [ 0.6629],\n",
      "        [ 0.8660],\n",
      "        [ 0.5559],\n",
      "        [ 0.5141],\n",
      "        [ 0.6127],\n",
      "        [ 0.5076],\n",
      "        [ 1.1588],\n",
      "        [ 0.3085],\n",
      "        [ 0.7328],\n",
      "        [ 0.4345],\n",
      "        [ 0.7733],\n",
      "        [ 0.4207],\n",
      "        [ 0.5899],\n",
      "        [ 0.6191],\n",
      "        [ 0.4913],\n",
      "        [ 0.3339],\n",
      "        [ 0.7808],\n",
      "        [ 0.8450],\n",
      "        [ 0.2275],\n",
      "        [ 0.4722],\n",
      "        [ 0.7097],\n",
      "        [ 0.5928],\n",
      "        [ 0.2778],\n",
      "        [ 0.6801],\n",
      "        [ 0.4547],\n",
      "        [ 0.7935],\n",
      "        [ 1.0668],\n",
      "        [ 0.5171],\n",
      "        [ 0.9728],\n",
      "        [ 0.3078],\n",
      "        [ 0.8804],\n",
      "        [ 0.5946],\n",
      "        [ 0.6510],\n",
      "        [ 0.9699],\n",
      "        [ 1.0574],\n",
      "        [ 0.3912],\n",
      "        [ 0.8720],\n",
      "        [ 0.3744],\n",
      "        [ 0.4081],\n",
      "        [ 0.2068],\n",
      "        [ 0.4094],\n",
      "        [ 0.7183],\n",
      "        [ 0.5883],\n",
      "        [ 0.1333],\n",
      "        [ 0.6657],\n",
      "        [ 0.4931],\n",
      "        [ 0.4303],\n",
      "        [ 0.3961],\n",
      "        [ 0.4117],\n",
      "        [ 0.4286],\n",
      "        [ 0.5398],\n",
      "        [ 0.3833],\n",
      "        [ 0.4854],\n",
      "        [ 0.4381],\n",
      "        [ 0.4166],\n",
      "        [ 0.6160],\n",
      "        [ 0.4993],\n",
      "        [ 0.5762],\n",
      "        [ 0.4192],\n",
      "        [ 0.3541],\n",
      "        [ 0.5381],\n",
      "        [ 0.3230],\n",
      "        [ 0.3306],\n",
      "        [ 0.5450],\n",
      "        [ 0.6156],\n",
      "        [ 0.5953],\n",
      "        [ 0.5005],\n",
      "        [ 1.1524],\n",
      "        [ 0.7333],\n",
      "        [ 0.9799],\n",
      "        [ 0.7966],\n",
      "        [ 0.3955],\n",
      "        [ 0.4552],\n",
      "        [ 0.5824],\n",
      "        [ 0.6358],\n",
      "        [ 0.4759],\n",
      "        [ 0.5572],\n",
      "        [ 1.3205],\n",
      "        [ 0.4899],\n",
      "        [ 0.5901],\n",
      "        [ 0.5703],\n",
      "        [ 0.2506],\n",
      "        [ 0.7397],\n",
      "        [ 0.7616],\n",
      "        [ 0.9627],\n",
      "        [ 0.8404],\n",
      "        [ 0.5957],\n",
      "        [ 0.5479],\n",
      "        [ 0.5800],\n",
      "        [ 0.5838],\n",
      "        [ 0.7042],\n",
      "        [ 0.8531],\n",
      "        [ 0.9232],\n",
      "        [ 0.3311],\n",
      "        [ 0.3143],\n",
      "        [ 0.7283],\n",
      "        [ 0.3834],\n",
      "        [ 0.8745],\n",
      "        [ 0.6618],\n",
      "        [ 0.3519],\n",
      "        [ 0.5939],\n",
      "        [ 0.6306],\n",
      "        [ 0.2343],\n",
      "        [ 0.7020],\n",
      "        [ 0.5250],\n",
      "        [ 0.4553],\n",
      "        [ 0.3209],\n",
      "        [ 0.6906],\n",
      "        [ 0.4936],\n",
      "        [ 0.4597],\n",
      "        [ 0.6199],\n",
      "        [ 0.7913],\n",
      "        [ 0.3787],\n",
      "        [ 0.7346],\n",
      "        [ 0.5646],\n",
      "        [ 0.7945],\n",
      "        [ 0.3182],\n",
      "        [ 1.1014],\n",
      "        [ 0.8198],\n",
      "        [ 0.5724],\n",
      "        [ 0.6079],\n",
      "        [ 0.4993],\n",
      "        [ 0.6711],\n",
      "        [ 0.4951],\n",
      "        [ 0.5582],\n",
      "        [ 0.8242],\n",
      "        [ 0.5389],\n",
      "        [ 0.3900],\n",
      "        [ 0.7073],\n",
      "        [ 0.9782],\n",
      "        [ 0.7865],\n",
      "        [ 0.5421],\n",
      "        [ 1.0864],\n",
      "        [ 0.5236],\n",
      "        [ 0.7567],\n",
      "        [ 0.8098],\n",
      "        [ 0.3768],\n",
      "        [ 1.3444],\n",
      "        [ 0.8531],\n",
      "        [ 0.4207],\n",
      "        [ 0.6468],\n",
      "        [ 0.4141],\n",
      "        [ 0.2520],\n",
      "        [ 0.6930],\n",
      "        [ 0.7082],\n",
      "        [ 0.6101],\n",
      "        [ 0.2983],\n",
      "        [ 0.4999],\n",
      "        [ 0.5947],\n",
      "        [ 0.4592],\n",
      "        [ 0.5791],\n",
      "        [ 0.4038],\n",
      "        [ 0.5627],\n",
      "        [ 0.4937],\n",
      "        [ 0.8188],\n",
      "        [ 0.6098],\n",
      "        [ 0.2871],\n",
      "        [ 0.4637],\n",
      "        [ 0.4712],\n",
      "        [ 0.2998],\n",
      "        [ 0.5896],\n",
      "        [ 0.3760],\n",
      "        [ 0.7910],\n",
      "        [ 0.5953],\n",
      "        [ 0.5543],\n",
      "        [ 0.5514],\n",
      "        [ 0.8945],\n",
      "        [ 0.6102],\n",
      "        [ 0.5800],\n",
      "        [ 0.3289],\n",
      "        [ 1.0243],\n",
      "        [ 0.7305],\n",
      "        [ 0.4799],\n",
      "        [ 0.5527],\n",
      "        [ 0.4416],\n",
      "        [ 1.2578],\n",
      "        [ 0.7109],\n",
      "        [ 0.4897],\n",
      "        [ 0.5705],\n",
      "        [ 0.4457],\n",
      "        [ 0.3848],\n",
      "        [ 0.7889],\n",
      "        [ 0.3249],\n",
      "        [ 0.8922],\n",
      "        [ 0.4476],\n",
      "        [ 0.7424],\n",
      "        [ 0.5053],\n",
      "        [ 0.6168],\n",
      "        [ 0.4862],\n",
      "        [ 0.3189]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"targets are\",test_data)\n",
    "print(\"predictions are\", model(train_data))\n",
    "\n",
    "#Since test_data is binary and train is not - we likely need to add activation function that converts the output to binary or so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
