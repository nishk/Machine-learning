{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: tensor(365.8415, grad_fn=<MseLossBackward>)\n",
      "\n",
      "Trained-model loss:  tensor(87.1207, grad_fn=<MseLossBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "#Variable declarations\n",
    "training_dataset = '/home/basic/Documents/Machine-learning/Projects/Boston-Housing/train.csv'\n",
    "df = pd.read_csv(training_dataset)\n",
    "dfh = df.head()\n",
    "target = df['medv']\n",
    "inputs = df.iloc[:,1:14]\n",
    "\n",
    "#Test/inference dataset\n",
    "test_dataset = '/home/basic/Documents/Machine-learning/Projects/Boston-Housing/test.csv'\n",
    "df1 = pd.read_csv(test_dataset)\n",
    "df1h = df1.head()\n",
    "test_inputs = df1.iloc[:,1:14]\n",
    "\n",
    "#Convert df to tensors\n",
    "torch_target = torch.Tensor(target)\n",
    "torch_inputs = torch.Tensor(inputs.values)\n",
    "test_inputs = torch.Tensor(test_inputs.values)\n",
    "\n",
    "#Define dataset\n",
    "train_ds = TensorDataset(torch_inputs,torch_target)\n",
    "\n",
    "#Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds,batch_size,shuffle=True)\n",
    "\n",
    "loss_fn = F.mse_loss\n",
    "#loss = loss_fn(model(torch_inputs),torch_target)\n",
    "\n",
    "#Create a function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xi,yi in train_dl:\n",
    "            pred = model(xi)\n",
    "            loss = loss_fn(pred,yi)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    \n",
    "    print('Trained-model loss: ',loss_fn(model(torch_inputs),torch_target))\n",
    "    #preds = model(torch_inputs)\n",
    "    #print(\"Predictions:\",preds)\n",
    "    #print(\"Targets:\",torch_target)\n",
    "    print('')\n",
    "\n",
    "#Define model\n",
    "class NeuralN1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(13,15)\n",
    "        self.linear2 = nn.Linear(15,15)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(15,7)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.linear4 = nn.Linear(7,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralN1()\n",
    "loss = loss_fn(model(torch_inputs),torch_target)\n",
    "print('Initial loss:', loss)\n",
    "print('')\n",
    "opt1 = torch.optim.SGD(model.parameters(), lr = 1e-5)\n",
    "opt2 = torch.optim.Adagrad(model.parameters(), lr = 1e-5)\n",
    "\n",
    "fit(100,model,loss_fn,opt1)\n",
    "#fit(100,model,loss_fn,opt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID     crim    zn  indus  chas    nox     rm    age     dis  rad  tax  \\\n",
      "0   3  0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242   \n",
      "1   6  0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222   \n",
      "2   8  0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311   \n",
      "3   9  0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311   \n",
      "4  10  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311   \n",
      "\n",
      "   ptratio   black  lstat  \n",
      "0     17.8  392.83   4.03  \n",
      "1     18.7  394.12   5.21  \n",
      "2     15.2  396.90  19.15  \n",
      "3     15.2  386.63  29.93  \n",
      "4     15.2  386.71  17.10  \n",
      "         crim    zn  indus  chas    nox     rm    age     dis  rad  tax  \\\n",
      "0     0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242   \n",
      "1     0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222   \n",
      "2     0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311   \n",
      "3     0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311   \n",
      "4     0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311   \n",
      "5     0.78420   0.0   8.14     0  0.538  5.990   81.7  4.2579    4  307   \n",
      "6     0.72580   0.0   8.14     0  0.538  5.727   69.5  3.7965    4  307   \n",
      "7     0.75026   0.0   8.14     0  0.538  5.924   94.1  4.3996    4  307   \n",
      "8     0.84054   0.0   8.14     0  0.538  5.599   85.7  4.4546    4  307   \n",
      "9     0.67191   0.0   8.14     0  0.538  5.813   90.3  4.6820    4  307   \n",
      "10    0.77299   0.0   8.14     0  0.538  6.495   94.4  4.4547    4  307   \n",
      "11    1.00245   0.0   8.14     0  0.538  6.674   87.3  4.2390    4  307   \n",
      "12    1.38799   0.0   8.14     0  0.538  5.950   82.0  3.9900    4  307   \n",
      "13    1.15172   0.0   8.14     0  0.538  5.701   95.0  3.7872    4  307   \n",
      "14    0.06417   0.0   5.96     0  0.499  5.933   68.2  3.3603    5  279   \n",
      "15    0.09744   0.0   5.96     0  0.499  5.841   61.4  3.3779    5  279   \n",
      "16    0.08014   0.0   5.96     0  0.499  5.850   41.5  3.9342    5  279   \n",
      "17    0.12744   0.0   6.91     0  0.448  6.770    2.9  5.7209    3  233   \n",
      "18    0.25387   0.0   6.91     0  0.448  5.399   95.3  5.8700    3  233   \n",
      "19    0.05360  21.0   5.64     0  0.439  6.511   21.1  6.8147    4  243   \n",
      "20    0.10328  25.0   5.13     0  0.453  5.927   47.2  6.9320    8  284   \n",
      "21    0.11027  25.0   5.13     0  0.453  6.456   67.8  7.2255    8  284   \n",
      "22    0.12816  12.5   6.07     0  0.409  5.885   33.0  6.4980    4  345   \n",
      "23    0.15876   0.0  10.81     0  0.413  5.961   17.5  5.2873    4  305   \n",
      "24    0.05646   0.0  12.83     0  0.437  6.232   53.7  5.0141    5  398   \n",
      "25    0.08387   0.0  12.83     0  0.437  5.874   36.6  4.5026    5  398   \n",
      "26    0.03659  25.0   4.86     0  0.426  6.302   32.2  5.4007    4  281   \n",
      "27    0.03932   0.0   3.41     0  0.489  6.405   73.9  3.0921    2  270   \n",
      "28    0.04203  28.0  15.04     0  0.464  6.442   53.6  3.6659    4  270   \n",
      "29    0.12204   0.0   2.89     0  0.445  6.625   57.8  3.4952    2  276   \n",
      "..        ...   ...    ...   ...    ...    ...    ...     ...  ...  ...   \n",
      "143  51.13580   0.0  18.10     0  0.597  5.757  100.0  1.4130   24  666   \n",
      "144  14.05070   0.0  18.10     0  0.597  6.657  100.0  1.5275   24  666   \n",
      "145  18.81100   0.0  18.10     0  0.597  4.628  100.0  1.5539   24  666   \n",
      "146  10.83420   0.0  18.10     0  0.679  6.782   90.8  1.8195   24  666   \n",
      "147  11.08740   0.0  18.10     0  0.718  6.411  100.0  1.8589   24  666   \n",
      "148   7.02259   0.0  18.10     0  0.718  6.006   95.3  1.8746   24  666   \n",
      "149  12.04820   0.0  18.10     0  0.614  5.648   87.6  1.9512   24  666   \n",
      "150   7.05042   0.0  18.10     0  0.614  6.103   85.1  2.0218   24  666   \n",
      "151  12.24720   0.0  18.10     0  0.584  5.837   59.7  1.9976   24  666   \n",
      "152   8.49213   0.0  18.10     0  0.584  6.348   86.1  2.0527   24  666   \n",
      "153  11.16040   0.0  18.10     0  0.740  6.629   94.6  2.1247   24  666   \n",
      "154  14.42080   0.0  18.10     0  0.740  6.461   93.3  2.0026   24  666   \n",
      "155  13.67810   0.0  18.10     0  0.740  5.935   87.9  1.8206   24  666   \n",
      "156   6.28807   0.0  18.10     0  0.740  6.341   96.4  2.0720   24  666   \n",
      "157   7.52601   0.0  18.10     0  0.713  6.417   98.3  2.1850   24  666   \n",
      "158   6.71772   0.0  18.10     0  0.713  6.749   92.6  2.3236   24  666   \n",
      "159   9.51363   0.0  18.10     0  0.713  6.728   94.1  2.4961   24  666   \n",
      "160   4.66883   0.0  18.10     0  0.713  5.976   87.9  2.5806   24  666   \n",
      "161   4.34879   0.0  18.10     0  0.580  6.167   84.0  3.0334   24  666   \n",
      "162   4.64689   0.0  18.10     0  0.614  6.980   67.6  2.5329   24  666   \n",
      "163   6.39312   0.0  18.10     0  0.584  6.162   97.4  2.2060   24  666   \n",
      "164   5.73116   0.0  18.10     0  0.532  7.061   77.0  3.4106   24  666   \n",
      "165   3.67367   0.0  18.10     0  0.583  6.312   51.9  3.9917   24  666   \n",
      "166   0.18337   0.0  27.74     0  0.609  5.414   98.3  1.7554    4  711   \n",
      "167   0.27957   0.0   9.69     0  0.585  5.926   42.6  2.3817    6  391   \n",
      "168   0.17899   0.0   9.69     0  0.585  5.670   28.8  2.7986    6  391   \n",
      "169   0.28960   0.0   9.69     0  0.585  5.390   72.9  2.7986    6  391   \n",
      "170   0.23912   0.0   9.69     0  0.585  6.019   65.3  2.4091    6  391   \n",
      "171   0.22438   0.0   9.69     0  0.585  6.027   79.7  2.4982    6  391   \n",
      "172   0.10959   0.0  11.93     0  0.573  6.794   89.3  2.3889    1  273   \n",
      "\n",
      "     ptratio   black  lstat  \n",
      "0       17.8  392.83   4.03  \n",
      "1       18.7  394.12   5.21  \n",
      "2       15.2  396.90  19.15  \n",
      "3       15.2  386.63  29.93  \n",
      "4       15.2  386.71  17.10  \n",
      "5       21.0  386.75  14.67  \n",
      "6       21.0  390.95  11.28  \n",
      "7       21.0  394.33  16.30  \n",
      "8       21.0  303.42  16.51  \n",
      "9       21.0  376.88  14.81  \n",
      "10      21.0  387.94  12.80  \n",
      "11      21.0  380.23  11.98  \n",
      "12      21.0  232.60  27.71  \n",
      "13      21.0  358.77  18.35  \n",
      "14      19.2  396.90   9.68  \n",
      "15      19.2  377.56  11.41  \n",
      "16      19.2  396.90   8.77  \n",
      "17      17.9  385.41   4.84  \n",
      "18      17.9  396.90  30.81  \n",
      "19      16.8  396.90   5.28  \n",
      "20      19.7  396.90   9.22  \n",
      "21      19.7  396.90   6.73  \n",
      "22      18.9  396.90   8.79  \n",
      "23      19.2  376.94   9.88  \n",
      "24      18.7  386.40  12.34  \n",
      "25      18.7  396.06   9.10  \n",
      "26      19.0  396.90   6.72  \n",
      "27      17.8  393.55   8.20  \n",
      "28      18.2  395.01   8.16  \n",
      "29      18.0  357.98   6.65  \n",
      "..       ...     ...    ...  \n",
      "143     20.2    2.60  10.11  \n",
      "144     20.2   35.05  21.22  \n",
      "145     20.2   28.79  34.37  \n",
      "146     20.2   21.57  25.79  \n",
      "147     20.2  318.75  15.02  \n",
      "148     20.2  319.98  15.70  \n",
      "149     20.2  291.55  14.10  \n",
      "150     20.2    2.52  23.29  \n",
      "151     20.2   24.65  15.69  \n",
      "152     20.2   83.45  17.64  \n",
      "153     20.2  109.85  23.27  \n",
      "154     20.2   27.49  18.05  \n",
      "155     20.2   68.95  34.02  \n",
      "156     20.2  318.01  17.79  \n",
      "157     20.2  304.21  19.31  \n",
      "158     20.2    0.32  17.44  \n",
      "159     20.2    6.68  18.71  \n",
      "160     20.2   10.48  19.01  \n",
      "161     20.2  396.90  16.29  \n",
      "162     20.2  374.68  11.66  \n",
      "163     20.2  302.76  24.10  \n",
      "164     20.2  395.28   7.01  \n",
      "165     20.2  388.62  10.58  \n",
      "166     20.1  344.05  23.97  \n",
      "167     19.2  396.90  13.59  \n",
      "168     19.2  393.29  17.60  \n",
      "169     19.2  396.90  21.14  \n",
      "170     19.2  396.90  12.92  \n",
      "171     19.2  396.90  14.33  \n",
      "172     21.0  393.45   6.48  \n",
      "\n",
      "[173 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1h)\n",
    "test_inputs = df1.iloc[:,1:14]\n",
    "print(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
