{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 13)\n",
      "(333, 1)\n",
      "(173, 13)\n",
      "Initial loss: tensor(576.9662, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "Epoch [10/700], Loss: 39.3553\n",
      "Epoch [20/700], Loss: 1.0513\n",
      "Epoch [30/700], Loss: 44.8135\n",
      "Epoch [40/700], Loss: 81.3599\n",
      "Epoch [50/700], Loss: 76.2958\n",
      "Epoch [60/700], Loss: 77.0627\n",
      "Epoch [70/700], Loss: 1.1493\n",
      "Epoch [80/700], Loss: 6.5673\n",
      "Epoch [90/700], Loss: 3.7127\n",
      "Epoch [100/700], Loss: 20.0601\n",
      "Epoch [110/700], Loss: 5.2343\n",
      "Epoch [120/700], Loss: 6.4701\n",
      "Epoch [130/700], Loss: 9.6244\n",
      "Epoch [140/700], Loss: 26.8297\n",
      "Epoch [150/700], Loss: 10.0623\n",
      "Epoch [160/700], Loss: 1.2357\n",
      "Epoch [170/700], Loss: 12.6565\n",
      "Epoch [180/700], Loss: 4.5228\n",
      "Epoch [190/700], Loss: 6.5821\n",
      "Epoch [200/700], Loss: 40.7922\n",
      "Epoch [210/700], Loss: 10.1084\n",
      "Epoch [220/700], Loss: 9.4607\n",
      "Epoch [230/700], Loss: 2.2697\n",
      "Epoch [240/700], Loss: 5.1337\n",
      "Epoch [250/700], Loss: 4.6316\n",
      "Epoch [260/700], Loss: 8.7035\n",
      "Epoch [270/700], Loss: 0.3802\n",
      "Epoch [280/700], Loss: 5.4813\n",
      "Epoch [290/700], Loss: 14.4177\n",
      "Epoch [300/700], Loss: 20.1804\n",
      "Epoch [310/700], Loss: 4.0753\n",
      "Epoch [320/700], Loss: 6.7220\n",
      "Epoch [330/700], Loss: 8.3957\n",
      "Epoch [340/700], Loss: 5.9978\n",
      "Epoch [350/700], Loss: 14.4641\n",
      "Epoch [360/700], Loss: 9.9802\n",
      "Epoch [370/700], Loss: 2.5313\n",
      "Epoch [380/700], Loss: 5.9711\n",
      "Epoch [390/700], Loss: 5.1797\n",
      "Epoch [400/700], Loss: 6.1560\n",
      "Epoch [410/700], Loss: 3.1992\n",
      "Epoch [420/700], Loss: 4.1383\n",
      "Epoch [430/700], Loss: 5.1717\n",
      "Epoch [440/700], Loss: 3.5938\n",
      "Epoch [450/700], Loss: 5.3229\n",
      "Epoch [460/700], Loss: 0.1394\n",
      "Epoch [470/700], Loss: 2.7236\n",
      "Epoch [480/700], Loss: 7.0187\n",
      "Epoch [490/700], Loss: 13.2153\n",
      "Epoch [500/700], Loss: 0.3623\n",
      "Epoch [510/700], Loss: 5.2447\n",
      "Epoch [520/700], Loss: 1.9582\n",
      "Epoch [530/700], Loss: 15.2332\n",
      "Epoch [540/700], Loss: 0.7483\n",
      "Epoch [550/700], Loss: 15.5681\n",
      "Epoch [560/700], Loss: 2.7702\n",
      "Epoch [570/700], Loss: 5.7912\n",
      "Epoch [580/700], Loss: 20.0779\n",
      "Epoch [590/700], Loss: 2.4917\n",
      "Epoch [600/700], Loss: 5.0849\n",
      "Epoch [610/700], Loss: 11.0554\n",
      "Epoch [620/700], Loss: 7.7655\n",
      "Epoch [630/700], Loss: 4.9129\n",
      "Epoch [640/700], Loss: 2.4174\n",
      "Epoch [650/700], Loss: 3.1185\n",
      "Epoch [660/700], Loss: 5.2555\n",
      "Epoch [670/700], Loss: 0.8023\n",
      "Epoch [680/700], Loss: 1.7363\n",
      "Epoch [690/700], Loss: 1.8881\n",
      "Epoch [700/700], Loss: 1.1672\n",
      "Trained-model loss:  tensor(3.6950, grad_fn=<MseLossBackward0>)\n",
      "Predictions: tensor([[27.9900],\n",
      "        [21.7412],\n",
      "        [37.1191],\n",
      "        [36.4509],\n",
      "        [21.5440],\n",
      "        [16.4726],\n",
      "        [19.7261],\n",
      "        [21.5038],\n",
      "        [21.0735],\n",
      "        [18.1833],\n",
      "        [21.3736],\n",
      "        [23.1137],\n",
      "        [17.6704],\n",
      "        [13.8863],\n",
      "        [17.4062],\n",
      "        [16.9139],\n",
      "        [15.2240],\n",
      "        [13.2241],\n",
      "        [13.3523],\n",
      "        [15.9954],\n",
      "        [12.8011],\n",
      "        [23.4301],\n",
      "        [31.8602],\n",
      "        [36.5334],\n",
      "        [25.8859],\n",
      "        [25.8167],\n",
      "        [21.4110],\n",
      "        [21.1812],\n",
      "        [21.1688],\n",
      "        [17.4336],\n",
      "        [18.5093],\n",
      "        [20.7793],\n",
      "        [21.5631],\n",
      "        [24.8822],\n",
      "        [18.3460],\n",
      "        [38.3771],\n",
      "        [27.9082],\n",
      "        [34.5577],\n",
      "        [24.8610],\n",
      "        [19.2106],\n",
      "        [16.7065],\n",
      "        [24.6228],\n",
      "        [33.9516],\n",
      "        [28.0379],\n",
      "        [22.2259],\n",
      "        [22.9796],\n",
      "        [19.7942],\n",
      "        [25.4467],\n",
      "        [25.4556],\n",
      "        [24.5770],\n",
      "        [24.9049],\n",
      "        [21.9439],\n",
      "        [20.7951],\n",
      "        [21.7063],\n",
      "        [28.6812],\n",
      "        [22.7365],\n",
      "        [23.6042],\n",
      "        [22.9087],\n",
      "        [25.4115],\n",
      "        [20.9103],\n",
      "        [22.2681],\n",
      "        [25.7796],\n",
      "        [27.7821],\n",
      "        [22.6418],\n",
      "        [25.0166],\n",
      "        [20.3053],\n",
      "        [20.4435],\n",
      "        [24.6042],\n",
      "        [26.2225],\n",
      "        [18.8763],\n",
      "        [19.9632],\n",
      "        [18.1864],\n",
      "        [19.7341],\n",
      "        [21.0899],\n",
      "        [19.1433],\n",
      "        [22.9335],\n",
      "        [21.4481],\n",
      "        [20.5374],\n",
      "        [21.0496],\n",
      "        [18.2016],\n",
      "        [19.9300],\n",
      "        [21.5259],\n",
      "        [20.7391],\n",
      "        [20.3553],\n",
      "        [17.6873],\n",
      "        [20.5635],\n",
      "        [15.8886],\n",
      "        [16.6438],\n",
      "        [18.7243],\n",
      "        [19.0451],\n",
      "        [17.6252],\n",
      "        [16.8937],\n",
      "        [16.7899],\n",
      "        [18.8456],\n",
      "        [15.1319],\n",
      "        [16.9343],\n",
      "        [16.3287],\n",
      "        [14.5493],\n",
      "        [13.8760],\n",
      "        [15.1189],\n",
      "        [15.0494],\n",
      "        [14.3419],\n",
      "        [19.7875],\n",
      "        [17.6793],\n",
      "        [17.9174],\n",
      "        [13.9215],\n",
      "        [24.0097],\n",
      "        [24.5242],\n",
      "        [25.2989],\n",
      "        [47.6776],\n",
      "        [50.1769],\n",
      "        [21.2884],\n",
      "        [22.8572],\n",
      "        [48.5531],\n",
      "        [19.1616],\n",
      "        [20.6735],\n",
      "        [16.9101],\n",
      "        [19.6574],\n",
      "        [19.6650],\n",
      "        [23.4197],\n",
      "        [22.8186],\n",
      "        [29.8911],\n",
      "        [24.6816],\n",
      "        [24.9980],\n",
      "        [26.6869],\n",
      "        [43.4734],\n",
      "        [40.1686],\n",
      "        [36.0875],\n",
      "        [38.7506],\n",
      "        [35.7633],\n",
      "        [48.1893],\n",
      "        [33.5538],\n",
      "        [34.1011],\n",
      "        [34.6289],\n",
      "        [33.5985],\n",
      "        [34.8589],\n",
      "        [34.6157],\n",
      "        [31.0485],\n",
      "        [28.2352],\n",
      "        [32.0658],\n",
      "        [27.5943],\n",
      "        [48.7750],\n",
      "        [51.2367],\n",
      "        [23.4794],\n",
      "        [22.5554],\n",
      "        [22.2935],\n",
      "        [16.6920],\n",
      "        [24.3411],\n",
      "        [23.1067],\n",
      "        [23.9802],\n",
      "        [20.8879],\n",
      "        [27.1179],\n",
      "        [26.0492],\n",
      "        [41.9904],\n",
      "        [43.5101],\n",
      "        [39.4482],\n",
      "        [29.2722],\n",
      "        [32.1586],\n",
      "        [23.4314],\n",
      "        [40.3957],\n",
      "        [41.8012],\n",
      "        [27.9249],\n",
      "        [24.2754],\n",
      "        [26.1198],\n",
      "        [24.1197],\n",
      "        [21.3203],\n",
      "        [28.2525],\n",
      "        [16.8774],\n",
      "        [23.0660],\n",
      "        [22.6982],\n",
      "        [26.8680],\n",
      "        [27.0777],\n",
      "        [28.4193],\n",
      "        [44.3965],\n",
      "        [32.5548],\n",
      "        [36.9838],\n",
      "        [45.8056],\n",
      "        [32.1856],\n",
      "        [34.4458],\n",
      "        [23.8371],\n",
      "        [28.8981],\n",
      "        [45.0863],\n",
      "        [26.0745],\n",
      "        [26.4689],\n",
      "        [38.7964],\n",
      "        [34.7731],\n",
      "        [38.6498],\n",
      "        [39.6476],\n",
      "        [48.2492],\n",
      "        [53.8936],\n",
      "        [32.9095],\n",
      "        [25.2378],\n",
      "        [21.3278],\n",
      "        [24.3354],\n",
      "        [32.6923],\n",
      "        [31.1732],\n",
      "        [25.1433],\n",
      "        [24.4091],\n",
      "        [21.2226],\n",
      "        [25.4036],\n",
      "        [25.1725],\n",
      "        [32.8477],\n",
      "        [37.6824],\n",
      "        [31.6000],\n",
      "        [35.9859],\n",
      "        [23.7383],\n",
      "        [20.4833],\n",
      "        [19.0889],\n",
      "        [24.7613],\n",
      "        [18.8051],\n",
      "        [19.4164],\n",
      "        [17.7448],\n",
      "        [19.8656],\n",
      "        [22.2967],\n",
      "        [24.1615],\n",
      "        [25.3398],\n",
      "        [26.9570],\n",
      "        [22.4775],\n",
      "        [20.0548],\n",
      "        [19.5862],\n",
      "        [24.6034],\n",
      "        [23.6405],\n",
      "        [20.6806],\n",
      "        [22.7566],\n",
      "        [21.4039],\n",
      "        [20.5345],\n",
      "        [32.4001],\n",
      "        [20.0858],\n",
      "        [25.9804],\n",
      "        [30.7143],\n",
      "        [26.1359],\n",
      "        [27.8796],\n",
      "        [26.1114],\n",
      "        [21.3366],\n",
      "        [16.4352],\n",
      "        [21.9240],\n",
      "        [22.0306],\n",
      "        [21.4051],\n",
      "        [26.9739],\n",
      "        [22.5188],\n",
      "        [27.9419],\n",
      "        [19.6736],\n",
      "        [23.0095],\n",
      "        [49.9412],\n",
      "        [50.4351],\n",
      "        [45.3386],\n",
      "        [51.0969],\n",
      "        [14.7889],\n",
      "        [13.1828],\n",
      "        [12.0444],\n",
      "        [13.2567],\n",
      "        [11.8638],\n",
      "        [12.8506],\n",
      "        [ 8.3337],\n",
      "        [ 7.6837],\n",
      "        [ 9.0419],\n",
      "        [12.7566],\n",
      "        [18.5031],\n",
      "        [11.0527],\n",
      "        [13.5920],\n",
      "        [14.8465],\n",
      "        [ 5.2365],\n",
      "        [ 7.7423],\n",
      "        [11.7510],\n",
      "        [ 9.0560],\n",
      "        [26.1614],\n",
      "        [16.5890],\n",
      "        [16.5639],\n",
      "        [ 7.9050],\n",
      "        [ 8.0570],\n",
      "        [10.9498],\n",
      "        [ 9.0753],\n",
      "        [ 9.7250],\n",
      "        [13.2754],\n",
      "        [ 8.8969],\n",
      "        [11.1355],\n",
      "        [11.3022],\n",
      "        [10.9441],\n",
      "        [13.4853],\n",
      "        [15.5526],\n",
      "        [14.9205],\n",
      "        [14.8472],\n",
      "        [ 8.8745],\n",
      "        [12.6494],\n",
      "        [ 9.4316],\n",
      "        [13.7976],\n",
      "        [16.0783],\n",
      "        [14.0685],\n",
      "        [11.2400],\n",
      "        [10.5597],\n",
      "        [14.7582],\n",
      "        [13.6567],\n",
      "        [17.1794],\n",
      "        [17.0861],\n",
      "        [16.7828],\n",
      "        [15.8980],\n",
      "        [14.4980],\n",
      "        [15.0064],\n",
      "        [19.7727],\n",
      "        [15.4441],\n",
      "        [20.3692],\n",
      "        [20.3161],\n",
      "        [21.9109],\n",
      "        [21.6596],\n",
      "        [20.0099],\n",
      "        [16.8564],\n",
      "        [17.7523],\n",
      "        [16.9017],\n",
      "        [20.1983],\n",
      "        [20.4318],\n",
      "        [21.8572],\n",
      "        [15.7663],\n",
      "        [16.5316],\n",
      "        [11.0512],\n",
      "        [14.4736],\n",
      "        [20.0957],\n",
      "        [22.7902],\n",
      "        [23.8316],\n",
      "        [22.0940],\n",
      "        [20.9713],\n",
      "        [20.3302],\n",
      "        [22.0202],\n",
      "        [13.5074],\n",
      "        [ 8.5051],\n",
      "        [13.8909],\n",
      "        [18.9784],\n",
      "        [21.0418],\n",
      "        [20.8632],\n",
      "        [20.3771],\n",
      "        [20.1879],\n",
      "        [18.1077],\n",
      "        [21.5062],\n",
      "        [17.4953]], grad_fn=<AddmmBackward0>)\n",
      "Targets: tensor([[24.0000],\n",
      "        [21.6000],\n",
      "        [33.4000],\n",
      "        [36.2000],\n",
      "        [22.9000],\n",
      "        [15.0000],\n",
      "        [18.9000],\n",
      "        [21.7000],\n",
      "        [20.4000],\n",
      "        [18.2000],\n",
      "        [19.9000],\n",
      "        [23.1000],\n",
      "        [20.2000],\n",
      "        [13.6000],\n",
      "        [19.6000],\n",
      "        [15.2000],\n",
      "        [14.5000],\n",
      "        [14.8000],\n",
      "        [12.7000],\n",
      "        [14.5000],\n",
      "        [13.5000],\n",
      "        [24.7000],\n",
      "        [30.8000],\n",
      "        [34.9000],\n",
      "        [25.3000],\n",
      "        [24.7000],\n",
      "        [21.2000],\n",
      "        [19.3000],\n",
      "        [20.0000],\n",
      "        [16.6000],\n",
      "        [19.4000],\n",
      "        [19.7000],\n",
      "        [20.5000],\n",
      "        [23.4000],\n",
      "        [18.9000],\n",
      "        [35.4000],\n",
      "        [24.7000],\n",
      "        [31.6000],\n",
      "        [23.3000],\n",
      "        [18.7000],\n",
      "        [16.0000],\n",
      "        [25.0000],\n",
      "        [33.0000],\n",
      "        [23.5000],\n",
      "        [19.4000],\n",
      "        [22.0000],\n",
      "        [17.4000],\n",
      "        [24.2000],\n",
      "        [22.8000],\n",
      "        [23.4000],\n",
      "        [24.1000],\n",
      "        [21.4000],\n",
      "        [20.0000],\n",
      "        [20.8000],\n",
      "        [28.0000],\n",
      "        [23.9000],\n",
      "        [22.9000],\n",
      "        [23.9000],\n",
      "        [26.6000],\n",
      "        [22.5000],\n",
      "        [22.2000],\n",
      "        [23.6000],\n",
      "        [28.7000],\n",
      "        [22.6000],\n",
      "        [25.0000],\n",
      "        [20.6000],\n",
      "        [21.4000],\n",
      "        [27.5000],\n",
      "        [26.5000],\n",
      "        [18.6000],\n",
      "        [19.3000],\n",
      "        [19.5000],\n",
      "        [20.4000],\n",
      "        [19.8000],\n",
      "        [19.4000],\n",
      "        [22.8000],\n",
      "        [18.5000],\n",
      "        [21.2000],\n",
      "        [19.2000],\n",
      "        [20.4000],\n",
      "        [19.3000],\n",
      "        [22.0000],\n",
      "        [20.3000],\n",
      "        [20.5000],\n",
      "        [17.3000],\n",
      "        [18.8000],\n",
      "        [15.7000],\n",
      "        [16.2000],\n",
      "        [18.0000],\n",
      "        [19.6000],\n",
      "        [18.4000],\n",
      "        [15.6000],\n",
      "        [17.4000],\n",
      "        [17.1000],\n",
      "        [13.3000],\n",
      "        [17.8000],\n",
      "        [14.4000],\n",
      "        [13.4000],\n",
      "        [13.8000],\n",
      "        [14.6000],\n",
      "        [17.8000],\n",
      "        [15.4000],\n",
      "        [21.5000],\n",
      "        [19.4000],\n",
      "        [17.0000],\n",
      "        [13.1000],\n",
      "        [24.3000],\n",
      "        [23.3000],\n",
      "        [27.0000],\n",
      "        [50.0000],\n",
      "        [50.0000],\n",
      "        [22.7000],\n",
      "        [25.0000],\n",
      "        [50.0000],\n",
      "        [23.8000],\n",
      "        [22.3000],\n",
      "        [17.4000],\n",
      "        [19.1000],\n",
      "        [23.1000],\n",
      "        [23.6000],\n",
      "        [22.6000],\n",
      "        [29.4000],\n",
      "        [23.2000],\n",
      "        [24.6000],\n",
      "        [29.9000],\n",
      "        [37.2000],\n",
      "        [39.8000],\n",
      "        [36.2000],\n",
      "        [37.9000],\n",
      "        [32.5000],\n",
      "        [50.0000],\n",
      "        [32.0000],\n",
      "        [34.9000],\n",
      "        [37.0000],\n",
      "        [30.5000],\n",
      "        [36.4000],\n",
      "        [31.1000],\n",
      "        [29.1000],\n",
      "        [30.3000],\n",
      "        [32.9000],\n",
      "        [24.1000],\n",
      "        [48.5000],\n",
      "        [50.0000],\n",
      "        [22.6000],\n",
      "        [24.4000],\n",
      "        [24.4000],\n",
      "        [19.3000],\n",
      "        [28.1000],\n",
      "        [23.7000],\n",
      "        [23.3000],\n",
      "        [21.7000],\n",
      "        [27.5000],\n",
      "        [30.1000],\n",
      "        [44.8000],\n",
      "        [50.0000],\n",
      "        [37.6000],\n",
      "        [31.6000],\n",
      "        [31.5000],\n",
      "        [24.3000],\n",
      "        [41.7000],\n",
      "        [48.3000],\n",
      "        [29.0000],\n",
      "        [24.0000],\n",
      "        [25.1000],\n",
      "        [22.0000],\n",
      "        [22.2000],\n",
      "        [23.7000],\n",
      "        [17.6000],\n",
      "        [24.3000],\n",
      "        [24.5000],\n",
      "        [26.2000],\n",
      "        [24.4000],\n",
      "        [24.8000],\n",
      "        [42.8000],\n",
      "        [33.8000],\n",
      "        [43.1000],\n",
      "        [48.8000],\n",
      "        [31.0000],\n",
      "        [36.5000],\n",
      "        [22.8000],\n",
      "        [30.7000],\n",
      "        [43.5000],\n",
      "        [25.2000],\n",
      "        [24.4000],\n",
      "        [35.2000],\n",
      "        [32.4000],\n",
      "        [35.1000],\n",
      "        [35.4000],\n",
      "        [46.0000],\n",
      "        [50.0000],\n",
      "        [32.2000],\n",
      "        [22.0000],\n",
      "        [20.1000],\n",
      "        [22.3000],\n",
      "        [28.5000],\n",
      "        [27.9000],\n",
      "        [23.9000],\n",
      "        [27.1000],\n",
      "        [20.3000],\n",
      "        [22.0000],\n",
      "        [26.4000],\n",
      "        [33.1000],\n",
      "        [36.1000],\n",
      "        [28.4000],\n",
      "        [33.4000],\n",
      "        [22.8000],\n",
      "        [20.3000],\n",
      "        [16.1000],\n",
      "        [22.1000],\n",
      "        [19.4000],\n",
      "        [16.2000],\n",
      "        [17.8000],\n",
      "        [19.8000],\n",
      "        [23.1000],\n",
      "        [23.8000],\n",
      "        [25.0000],\n",
      "        [24.6000],\n",
      "        [22.2000],\n",
      "        [19.3000],\n",
      "        [19.8000],\n",
      "        [22.2000],\n",
      "        [20.7000],\n",
      "        [19.5000],\n",
      "        [20.6000],\n",
      "        [19.0000],\n",
      "        [18.7000],\n",
      "        [32.7000],\n",
      "        [16.5000],\n",
      "        [23.9000],\n",
      "        [31.2000],\n",
      "        [23.1000],\n",
      "        [24.5000],\n",
      "        [26.6000],\n",
      "        [18.6000],\n",
      "        [17.8000],\n",
      "        [21.7000],\n",
      "        [22.7000],\n",
      "        [22.6000],\n",
      "        [25.0000],\n",
      "        [20.8000],\n",
      "        [27.5000],\n",
      "        [21.9000],\n",
      "        [23.1000],\n",
      "        [50.0000],\n",
      "        [50.0000],\n",
      "        [50.0000],\n",
      "        [50.0000],\n",
      "        [13.8000],\n",
      "        [13.8000],\n",
      "        [13.9000],\n",
      "        [13.3000],\n",
      "        [11.3000],\n",
      "        [12.3000],\n",
      "        [ 8.8000],\n",
      "        [10.5000],\n",
      "        [ 7.4000],\n",
      "        [11.5000],\n",
      "        [23.2000],\n",
      "        [ 9.7000],\n",
      "        [12.7000],\n",
      "        [12.5000],\n",
      "        [ 5.0000],\n",
      "        [ 5.6000],\n",
      "        [ 7.2000],\n",
      "        [ 8.3000],\n",
      "        [27.9000],\n",
      "        [17.2000],\n",
      "        [16.3000],\n",
      "        [ 7.0000],\n",
      "        [ 7.2000],\n",
      "        [10.4000],\n",
      "        [ 8.8000],\n",
      "        [ 8.4000],\n",
      "        [11.7000],\n",
      "        [ 8.3000],\n",
      "        [10.9000],\n",
      "        [11.0000],\n",
      "        [ 9.5000],\n",
      "        [14.1000],\n",
      "        [16.1000],\n",
      "        [14.3000],\n",
      "        [11.7000],\n",
      "        [ 8.7000],\n",
      "        [12.8000],\n",
      "        [10.5000],\n",
      "        [17.1000],\n",
      "        [18.4000],\n",
      "        [15.4000],\n",
      "        [10.8000],\n",
      "        [11.8000],\n",
      "        [12.6000],\n",
      "        [14.1000],\n",
      "        [15.2000],\n",
      "        [16.1000],\n",
      "        [17.8000],\n",
      "        [14.1000],\n",
      "        [13.5000],\n",
      "        [14.9000],\n",
      "        [20.0000],\n",
      "        [16.4000],\n",
      "        [17.7000],\n",
      "        [19.5000],\n",
      "        [20.2000],\n",
      "        [21.4000],\n",
      "        [19.9000],\n",
      "        [19.0000],\n",
      "        [19.1000],\n",
      "        [19.1000],\n",
      "        [20.1000],\n",
      "        [19.6000],\n",
      "        [23.2000],\n",
      "        [13.8000],\n",
      "        [16.7000],\n",
      "        [12.0000],\n",
      "        [14.6000],\n",
      "        [21.4000],\n",
      "        [23.0000],\n",
      "        [23.7000],\n",
      "        [21.8000],\n",
      "        [20.6000],\n",
      "        [19.1000],\n",
      "        [20.6000],\n",
      "        [15.2000],\n",
      "        [ 8.1000],\n",
      "        [13.6000],\n",
      "        [20.1000],\n",
      "        [21.8000],\n",
      "        [18.3000],\n",
      "        [17.5000],\n",
      "        [22.4000],\n",
      "        [20.6000],\n",
      "        [23.9000],\n",
      "        [11.9000]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "#Variable declarations\n",
    "train_data = '~/Downloads/Machine-learning/Projects/Boston-Housing/train.csv'\n",
    "train_df = pd.read_csv(train_data)\n",
    "dfh = train_df.head()\n",
    "target = train_df.iloc[:,14:15]\n",
    "inputs = train_df.iloc[:,1:14]\n",
    "\n",
    "#Test/inference dataset\n",
    "test_data = '~/Downloads/Machine-learning/Projects/Boston-Housing/test.csv'\n",
    "test_df = pd.read_csv(test_data)\n",
    "df1h = test_df.head()\n",
    "test_inputs = test_df.iloc[:,1:14]\n",
    "\n",
    "print(inputs.shape)\n",
    "print(target.shape)\n",
    "print(test_inputs.shape)\n",
    "\n",
    "#Convert df to tensors\n",
    "torch_target = torch.Tensor(target.values)\n",
    "torch_inputs = torch.Tensor(inputs.values)\n",
    "test_inputs = torch.Tensor(test_inputs.values)\n",
    "\n",
    "#Define dataset\n",
    "train_ds = TensorDataset(torch_inputs,torch_target)\n",
    "\n",
    "#Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds,batch_size,shuffle=True)\n",
    "\n",
    "loss_fn = F.mse_loss\n",
    "pred = torch.Tensor()\n",
    "#loss = loss_fn(model(torch_inputs),torch_target)\n",
    "\n",
    "#Create a function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xi,yi in train_dl:\n",
    "            pred = model(xi)\n",
    "            loss = loss_fn(pred,yi)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        if (epoch+1) % 10 ==0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "    \n",
    "    print('Trained-model loss: ',loss_fn(model(torch_inputs),torch_target))\n",
    "    preds = model(torch_inputs)\n",
    "    print(\"Predictions:\",preds)\n",
    "    print(\"Targets:\",torch_target)\n",
    "    print('')\n",
    "\n",
    "#Define model\n",
    "class NeuralN1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(13,75)\n",
    "        self.linear2 = nn.Linear(75,50)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(50,25)\n",
    "        #self.act2 = nn.ReLU()\n",
    "        self.linear4 = nn.Linear(25,12)\n",
    "        self.linear5 = nn.Linear(12,5)\n",
    "        self.linear6 = nn.Linear(5,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.act1(self.linear1(x))\n",
    "        x = self.act1(self.linear2(x))\n",
    "        #x = self.act1(x)\n",
    "        x = self.act1(self.linear3(x))\n",
    "        #x = self.act2(x)\n",
    "        x = self.act1(self.linear4(x))\n",
    "        x = self.act1(self.linear5(x))\n",
    "        x = self.linear6(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralN1()\n",
    "loss = loss_fn(model(torch_inputs),torch_target)\n",
    "print('Initial loss:', loss)\n",
    "print('')\n",
    "opt1 = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "opt2 = torch.optim.Adagrad(model.parameters(), lr = 1e-5)\n",
    "\n",
    "fit(700,model,loss_fn,opt1)\n",
    "pred = model(torch_inputs)\n",
    "#print(pred)\n",
    "#fit(100,model,loss_fn,opt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
