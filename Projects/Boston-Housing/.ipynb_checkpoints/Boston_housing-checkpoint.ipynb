{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: tensor(592.3829, grad_fn=<MseLossBackward>)\n",
      "\n",
      "Trained-model loss:  tensor(2.7030, grad_fn=<MseLossBackward>)\n",
      "\n",
      "tensor([[27.4322],\n",
      "        [19.8075],\n",
      "        [34.6352],\n",
      "        [33.6311],\n",
      "        [22.3822],\n",
      "        [17.0411],\n",
      "        [20.5451],\n",
      "        [22.3138],\n",
      "        [22.4214],\n",
      "        [19.3110],\n",
      "        [23.0094],\n",
      "        [24.0658],\n",
      "        [19.2828],\n",
      "        [14.5919],\n",
      "        [18.0602],\n",
      "        [16.8975],\n",
      "        [15.5530],\n",
      "        [14.0691],\n",
      "        [14.2583],\n",
      "        [17.1857],\n",
      "        [13.7299],\n",
      "        [24.4440],\n",
      "        [29.5413],\n",
      "        [33.3280],\n",
      "        [25.2894],\n",
      "        [25.0259],\n",
      "        [20.9357],\n",
      "        [20.8116],\n",
      "        [19.9317],\n",
      "        [17.2645],\n",
      "        [19.4602],\n",
      "        [20.9410],\n",
      "        [20.3670],\n",
      "        [24.2505],\n",
      "        [21.1493],\n",
      "        [34.3605],\n",
      "        [25.8774],\n",
      "        [32.6536],\n",
      "        [24.0857],\n",
      "        [19.7010],\n",
      "        [16.3812],\n",
      "        [24.8160],\n",
      "        [31.2765],\n",
      "        [25.8887],\n",
      "        [21.3641],\n",
      "        [22.9528],\n",
      "        [19.0568],\n",
      "        [24.2796],\n",
      "        [24.1735],\n",
      "        [23.7117],\n",
      "        [24.0069],\n",
      "        [22.1795],\n",
      "        [20.3534],\n",
      "        [21.8477],\n",
      "        [27.7527],\n",
      "        [22.7920],\n",
      "        [23.4349],\n",
      "        [21.9843],\n",
      "        [26.5559],\n",
      "        [21.8893],\n",
      "        [22.1845],\n",
      "        [24.6463],\n",
      "        [28.7327],\n",
      "        [22.2086],\n",
      "        [24.7932],\n",
      "        [19.0251],\n",
      "        [20.9171],\n",
      "        [24.5206],\n",
      "        [26.0155],\n",
      "        [18.7793],\n",
      "        [20.4255],\n",
      "        [17.7259],\n",
      "        [19.9325],\n",
      "        [22.6580],\n",
      "        [19.0449],\n",
      "        [21.6545],\n",
      "        [20.2794],\n",
      "        [21.0087],\n",
      "        [20.1271],\n",
      "        [19.6219],\n",
      "        [20.4509],\n",
      "        [21.8702],\n",
      "        [20.6333],\n",
      "        [19.1472],\n",
      "        [16.7669],\n",
      "        [19.1615],\n",
      "        [16.1162],\n",
      "        [18.0931],\n",
      "        [19.4040],\n",
      "        [20.2548],\n",
      "        [18.4609],\n",
      "        [18.1950],\n",
      "        [18.0161],\n",
      "        [19.7489],\n",
      "        [16.4864],\n",
      "        [18.1811],\n",
      "        [16.4926],\n",
      "        [14.6653],\n",
      "        [14.6425],\n",
      "        [14.7864],\n",
      "        [16.3538],\n",
      "        [15.0254],\n",
      "        [20.1996],\n",
      "        [21.2854],\n",
      "        [19.2253],\n",
      "        [13.7813],\n",
      "        [24.3480],\n",
      "        [25.1174],\n",
      "        [27.4371],\n",
      "        [49.3464],\n",
      "        [51.0616],\n",
      "        [22.6479],\n",
      "        [27.3740],\n",
      "        [49.6284],\n",
      "        [21.5355],\n",
      "        [20.6894],\n",
      "        [18.4886],\n",
      "        [20.0412],\n",
      "        [20.4715],\n",
      "        [24.9222],\n",
      "        [23.8277],\n",
      "        [30.5000],\n",
      "        [25.1093],\n",
      "        [27.7915],\n",
      "        [29.0410],\n",
      "        [40.9655],\n",
      "        [37.2647],\n",
      "        [34.9118],\n",
      "        [36.2085],\n",
      "        [31.3728],\n",
      "        [48.5250],\n",
      "        [33.0527],\n",
      "        [35.7192],\n",
      "        [33.9739],\n",
      "        [34.4548],\n",
      "        [37.6655],\n",
      "        [31.8076],\n",
      "        [28.9900],\n",
      "        [29.8092],\n",
      "        [33.8397],\n",
      "        [26.2369],\n",
      "        [44.0948],\n",
      "        [46.1479],\n",
      "        [24.0116],\n",
      "        [23.9849],\n",
      "        [22.2215],\n",
      "        [18.0965],\n",
      "        [25.2862],\n",
      "        [23.7451],\n",
      "        [24.4815],\n",
      "        [20.8333],\n",
      "        [29.2797],\n",
      "        [28.6541],\n",
      "        [45.2979],\n",
      "        [45.1134],\n",
      "        [42.2052],\n",
      "        [33.4346],\n",
      "        [32.1613],\n",
      "        [23.2196],\n",
      "        [45.4401],\n",
      "        [46.9442],\n",
      "        [30.0996],\n",
      "        [24.0819],\n",
      "        [28.4173],\n",
      "        [23.6689],\n",
      "        [21.9003],\n",
      "        [27.9525],\n",
      "        [17.8655],\n",
      "        [23.8556],\n",
      "        [22.9761],\n",
      "        [25.8430],\n",
      "        [25.9549],\n",
      "        [29.4576],\n",
      "        [39.8865],\n",
      "        [32.2444],\n",
      "        [42.3802],\n",
      "        [45.9837],\n",
      "        [32.2192],\n",
      "        [37.9127],\n",
      "        [23.6390],\n",
      "        [27.0999],\n",
      "        [43.0004],\n",
      "        [24.9458],\n",
      "        [23.2590],\n",
      "        [33.3633],\n",
      "        [32.5654],\n",
      "        [35.3592],\n",
      "        [35.8380],\n",
      "        [43.6532],\n",
      "        [49.5675],\n",
      "        [29.2801],\n",
      "        [23.6295],\n",
      "        [20.8065],\n",
      "        [22.7654],\n",
      "        [28.0866],\n",
      "        [26.9127],\n",
      "        [25.5763],\n",
      "        [25.4725],\n",
      "        [21.6400],\n",
      "        [25.0107],\n",
      "        [25.6453],\n",
      "        [34.5577],\n",
      "        [34.3530],\n",
      "        [28.4800],\n",
      "        [33.7595],\n",
      "        [25.2837],\n",
      "        [21.3319],\n",
      "        [16.6782],\n",
      "        [24.7988],\n",
      "        [20.4986],\n",
      "        [20.7302],\n",
      "        [18.1042],\n",
      "        [20.0700],\n",
      "        [23.1463],\n",
      "        [24.2734],\n",
      "        [25.7645],\n",
      "        [24.7844],\n",
      "        [23.3289],\n",
      "        [20.0412],\n",
      "        [19.8900],\n",
      "        [23.6719],\n",
      "        [22.3369],\n",
      "        [19.6162],\n",
      "        [20.8633],\n",
      "        [19.8737],\n",
      "        [19.7013],\n",
      "        [31.1479],\n",
      "        [18.4550],\n",
      "        [25.2148],\n",
      "        [32.4478],\n",
      "        [24.7586],\n",
      "        [26.3324],\n",
      "        [24.9853],\n",
      "        [21.0888],\n",
      "        [17.4098],\n",
      "        [21.2463],\n",
      "        [22.5096],\n",
      "        [21.9556],\n",
      "        [27.0742],\n",
      "        [23.2584],\n",
      "        [26.9940],\n",
      "        [22.7757],\n",
      "        [20.3580],\n",
      "        [50.0352],\n",
      "        [52.9711],\n",
      "        [51.0646],\n",
      "        [52.6178],\n",
      "        [13.6092],\n",
      "        [13.6232],\n",
      "        [13.0359],\n",
      "        [13.9770],\n",
      "        [12.4209],\n",
      "        [12.4729],\n",
      "        [ 8.2688],\n",
      "        [ 9.3887],\n",
      "        [ 8.1119],\n",
      "        [13.5432],\n",
      "        [20.5336],\n",
      "        [10.5003],\n",
      "        [14.7140],\n",
      "        [17.0903],\n",
      "        [ 4.6549],\n",
      "        [ 6.3635],\n",
      "        [11.4606],\n",
      "        [ 9.1703],\n",
      "        [31.3510],\n",
      "        [16.6792],\n",
      "        [16.5423],\n",
      "        [ 7.4835],\n",
      "        [ 7.1495],\n",
      "        [10.2882],\n",
      "        [ 9.3118],\n",
      "        [ 8.8989],\n",
      "        [12.9108],\n",
      "        [ 9.5037],\n",
      "        [10.8520],\n",
      "        [11.5858],\n",
      "        [11.7856],\n",
      "        [14.0085],\n",
      "        [16.4784],\n",
      "        [16.0652],\n",
      "        [13.3857],\n",
      "        [ 9.4411],\n",
      "        [13.4510],\n",
      "        [10.2477],\n",
      "        [14.8224],\n",
      "        [17.0356],\n",
      "        [14.5746],\n",
      "        [11.4033],\n",
      "        [11.3308],\n",
      "        [15.9491],\n",
      "        [15.0575],\n",
      "        [17.2106],\n",
      "        [18.1958],\n",
      "        [18.6544],\n",
      "        [16.5528],\n",
      "        [14.8926],\n",
      "        [16.0215],\n",
      "        [20.0411],\n",
      "        [16.9879],\n",
      "        [20.3316],\n",
      "        [20.6911],\n",
      "        [21.9812],\n",
      "        [21.5920],\n",
      "        [20.5439],\n",
      "        [17.4658],\n",
      "        [17.9907],\n",
      "        [19.0275],\n",
      "        [20.3443],\n",
      "        [20.4768],\n",
      "        [22.1307],\n",
      "        [15.5488],\n",
      "        [18.2423],\n",
      "        [13.8618],\n",
      "        [15.0007],\n",
      "        [20.7719],\n",
      "        [23.5612],\n",
      "        [25.2605],\n",
      "        [23.2388],\n",
      "        [21.7743],\n",
      "        [21.1264],\n",
      "        [22.5031],\n",
      "        [15.0951],\n",
      "        [ 7.9533],\n",
      "        [14.9482],\n",
      "        [20.5580],\n",
      "        [21.8772],\n",
      "        [20.4796],\n",
      "        [19.6853],\n",
      "        [21.2885],\n",
      "        [18.7610],\n",
      "        [21.6029],\n",
      "        [17.2821]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "#Variable declarations\n",
    "#training_dataset = '/home/basic/Documents/Machine-learning/Projects/Boston-Housing/train.csv'\n",
    "training_dataset = '/Users/anishkirloskar/Documents/Machine-learning/Projects/Boston-Housing/train.csv'\n",
    "df = pd.read_csv(training_dataset)\n",
    "dfh = df.head()\n",
    "target = df.iloc[:,14:15]\n",
    "inputs = df.iloc[:,1:14]\n",
    "\n",
    "#Test/inference dataset\n",
    "#test_dataset = '/home/basic/Documents/Machine-learning/Projects/Boston-Housing/test.csv'\n",
    "test_dataset = '/Users/anishkirloskar/Documents/Machine-learning/Projects/Boston-Housing/test.csv'\n",
    "df1 = pd.read_csv(test_dataset)\n",
    "df1h = df1.head()\n",
    "test_inputs = df1.iloc[:,1:14]\n",
    "\n",
    "#Convert df to tensors\n",
    "torch_target = torch.Tensor(target.values)\n",
    "torch_inputs = torch.Tensor(inputs.values)\n",
    "test_inputs = torch.Tensor(test_inputs.values)\n",
    "\n",
    "#Define dataset\n",
    "train_ds = TensorDataset(torch_inputs,torch_target)\n",
    "\n",
    "#Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds,batch_size,shuffle=True)\n",
    "\n",
    "loss_fn = F.mse_loss\n",
    "pred = torch.Tensor()\n",
    "#loss = loss_fn(model(torch_inputs),torch_target)\n",
    "\n",
    "#Create a function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xi,yi in train_dl:\n",
    "            pred = model(xi)\n",
    "            loss = loss_fn(pred,yi)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    \n",
    "    print('Trained-model loss: ',loss_fn(model(torch_inputs),torch_target))\n",
    "    #preds = model(torch_inputs)\n",
    "    #print(\"Predictions:\",preds)\n",
    "    #print(\"Targets:\",torch_target)\n",
    "    print('')\n",
    "\n",
    "#Define model\n",
    "class NeuralN1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(13,75)\n",
    "        self.linear2 = nn.Linear(75,50)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(50,25)\n",
    "        #self.act2 = nn.ReLU()\n",
    "        self.linear4 = nn.Linear(25,12)\n",
    "        self.linear5 = nn.Linear(12,5)\n",
    "        self.linear6 = nn.Linear(5,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.act1(self.linear1(x))\n",
    "        x = self.act1(self.linear2(x))\n",
    "        #x = self.act1(x)\n",
    "        x = self.act1(self.linear3(x))\n",
    "        #x = self.act2(x)\n",
    "        x = self.act1(self.linear4(x))\n",
    "        x = self.act1(self.linear5(x))\n",
    "        x = self.linear6(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralN1()\n",
    "loss = loss_fn(model(torch_inputs),torch_target)\n",
    "print('Initial loss:', loss)\n",
    "print('')\n",
    "opt1 = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "opt2 = torch.optim.Adagrad(model.parameters(), lr = 1e-5)\n",
    "\n",
    "fit(700,model,loss_fn,opt1)\n",
    "pred = model(torch_inputs)\n",
    "print(pred)\n",
    "#fit(100,model,loss_fn,opt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0055],\n",
      "        [-0.6204],\n",
      "        [-0.3561],\n",
      "        [-2.9151],\n",
      "        [-1.2247],\n",
      "        [ 1.3507],\n",
      "        [ 0.0656],\n",
      "        [-0.3491],\n",
      "        [ 1.6326],\n",
      "        [-0.2020],\n",
      "        [ 2.0053],\n",
      "        [-0.0404],\n",
      "        [-2.5254],\n",
      "        [-0.0186],\n",
      "        [-3.0810],\n",
      "        [ 0.6767],\n",
      "        [ 0.1048],\n",
      "        [-1.2269],\n",
      "        [ 0.4945],\n",
      "        [ 1.3695],\n",
      "        [-0.5216],\n",
      "        [-1.4580],\n",
      "        [-2.5943],\n",
      "        [-1.8603],\n",
      "        [-1.2453],\n",
      "        [-1.1032],\n",
      "        [-1.2278],\n",
      "        [ 0.6329],\n",
      "        [ 0.9672],\n",
      "        [ 1.9896],\n",
      "        [-0.0496],\n",
      "        [ 1.3404],\n",
      "        [-0.3354],\n",
      "        [-0.9508],\n",
      "        [-0.4684],\n",
      "        [-3.2061],\n",
      "        [-0.2322],\n",
      "        [-0.8626],\n",
      "        [ 0.9385],\n",
      "        [ 0.5237],\n",
      "        [-0.0701],\n",
      "        [-0.6826],\n",
      "        [-2.6195],\n",
      "        [ 1.9755],\n",
      "        [ 0.1072],\n",
      "        [ 0.7246],\n",
      "        [ 3.7360],\n",
      "        [-0.0833],\n",
      "        [ 1.2630],\n",
      "        [ 0.0584],\n",
      "        [ 0.5223],\n",
      "        [ 0.3582],\n",
      "        [ 0.4331],\n",
      "        [ 0.7902],\n",
      "        [-3.4474],\n",
      "        [-2.3127],\n",
      "        [-0.0237],\n",
      "        [-3.0198],\n",
      "        [-2.3531],\n",
      "        [-1.1332],\n",
      "        [-1.2506],\n",
      "        [ 1.6161],\n",
      "        [-1.0419],\n",
      "        [-1.2418],\n",
      "        [ 0.3971],\n",
      "        [-1.6072],\n",
      "        [-1.1284],\n",
      "        [-3.3634],\n",
      "        [-1.5623],\n",
      "        [-0.1886],\n",
      "        [ 0.9231],\n",
      "        [-2.0758],\n",
      "        [-0.8253],\n",
      "        [ 1.1511],\n",
      "        [-0.6431],\n",
      "        [-0.1182],\n",
      "        [ 2.7837],\n",
      "        [-0.4793],\n",
      "        [ 2.0967],\n",
      "        [-4.2244],\n",
      "        [ 0.3464],\n",
      "        [-0.9756],\n",
      "        [-0.8148],\n",
      "        [-1.3145],\n",
      "        [ 0.1082],\n",
      "        [ 0.5288],\n",
      "        [ 0.4705],\n",
      "        [ 0.9301],\n",
      "        [ 0.5471],\n",
      "        [ 0.3518],\n",
      "        [-0.8597],\n",
      "        [ 2.1047],\n",
      "        [-0.5768],\n",
      "        [ 1.7549],\n",
      "        [ 2.1915],\n",
      "        [-0.4484],\n",
      "        [ 1.8041],\n",
      "        [ 1.1548],\n",
      "        [ 0.1793],\n",
      "        [ 1.1276],\n",
      "        [-2.9453],\n",
      "        [-1.7419],\n",
      "        [-2.3854],\n",
      "        [ 1.2087],\n",
      "        [ 1.3144],\n",
      "        [-0.3205],\n",
      "        [ 0.0257],\n",
      "        [ 1.5259],\n",
      "        [ 0.0571],\n",
      "        [-3.1826],\n",
      "        [-0.2897],\n",
      "        [-1.5511],\n",
      "        [ 0.8317],\n",
      "        [-3.6271],\n",
      "        [-2.5663],\n",
      "        [-1.8328],\n",
      "        [-0.0815],\n",
      "        [ 0.5126],\n",
      "        [-3.1865],\n",
      "        [ 0.9310],\n",
      "        [ 0.6724],\n",
      "        [-0.0540],\n",
      "        [ 1.3503],\n",
      "        [ 1.5759],\n",
      "        [-2.9873],\n",
      "        [ 1.9132],\n",
      "        [-2.5969],\n",
      "        [-1.7361],\n",
      "        [-2.6499],\n",
      "        [ 0.1109],\n",
      "        [-6.2214],\n",
      "        [-0.7361],\n",
      "        [-1.3935],\n",
      "        [-3.7145],\n",
      "        [ 2.2879],\n",
      "        [-0.5656],\n",
      "        [-1.7957],\n",
      "        [-1.3918],\n",
      "        [-7.3843],\n",
      "        [-1.3242],\n",
      "        [-1.2843],\n",
      "        [-5.7717],\n",
      "        [-2.6036],\n",
      "        [ 0.5327],\n",
      "        [-1.2737],\n",
      "        [-2.8182],\n",
      "        [-1.9638],\n",
      "        [-4.1195],\n",
      "        [ 0.1370],\n",
      "        [ 0.6192],\n",
      "        [-0.7124],\n",
      "        [ 0.9005],\n",
      "        [-3.2041],\n",
      "        [-1.9006],\n",
      "        [-6.7771],\n",
      "        [ 3.4064],\n",
      "        [-2.0586],\n",
      "        [ 1.7191],\n",
      "        [-0.8068],\n",
      "        [ 0.9192],\n",
      "        [-4.7344],\n",
      "        [ 0.1316],\n",
      "        [-0.0532],\n",
      "        [ 2.4719],\n",
      "        [ 1.3823],\n",
      "        [-0.9900],\n",
      "        [ 1.0884],\n",
      "        [-0.7011],\n",
      "        [-1.8987],\n",
      "        [-2.9276],\n",
      "        [-1.1316],\n",
      "        [ 0.8129],\n",
      "        [ 1.4444],\n",
      "        [-5.8069],\n",
      "        [-2.4606],\n",
      "        [-2.5604],\n",
      "        [-2.0570],\n",
      "        [-0.0184],\n",
      "        [-1.2752],\n",
      "        [ 2.4893],\n",
      "        [-3.0739],\n",
      "        [-2.3250],\n",
      "        [-1.2888],\n",
      "        [-1.8717],\n",
      "        [-2.7769],\n",
      "        [-1.7526],\n",
      "        [ 0.1126],\n",
      "        [-0.8976],\n",
      "        [-3.6871],\n",
      "        [-1.3532],\n",
      "        [-4.7206],\n",
      "        [ 2.9501],\n",
      "        [ 0.3941],\n",
      "        [ 0.8770],\n",
      "        [ 0.3036],\n",
      "        [-1.4107],\n",
      "        [ 0.8562],\n",
      "        [-1.8065],\n",
      "        [ 0.6286],\n",
      "        [ 2.0627],\n",
      "        [-2.1670],\n",
      "        [-1.2174],\n",
      "        [-2.6953],\n",
      "        [-0.5390],\n",
      "        [-0.2248],\n",
      "        [ 1.9984],\n",
      "        [ 0.6065],\n",
      "        [ 2.2204],\n",
      "        [ 1.6167],\n",
      "        [-0.3193],\n",
      "        [ 2.6556],\n",
      "        [-0.5267],\n",
      "        [-0.7534],\n",
      "        [-0.5738],\n",
      "        [ 0.1925],\n",
      "        [-1.5554],\n",
      "        [-0.4953],\n",
      "        [-0.1040],\n",
      "        [ 0.2870],\n",
      "        [-1.0009],\n",
      "        [ 0.5275],\n",
      "        [ 0.7800],\n",
      "        [-0.2361],\n",
      "        [-0.2086],\n",
      "        [ 0.6874],\n",
      "        [ 1.9553],\n",
      "        [-3.1728],\n",
      "        [ 3.5028],\n",
      "        [ 0.1364],\n",
      "        [-2.1741],\n",
      "        [-1.8941],\n",
      "        [ 0.8606],\n",
      "        [-2.7440],\n",
      "        [ 0.7240],\n",
      "        [-0.7888],\n",
      "        [-0.8140],\n",
      "        [-1.6767],\n",
      "        [-2.2935],\n",
      "        [ 1.4713],\n",
      "        [ 0.6659],\n",
      "        [-1.0244],\n",
      "        [ 0.1850],\n",
      "        [ 0.2767],\n",
      "        [-0.3563],\n",
      "        [-0.6594],\n",
      "        [-1.6403],\n",
      "        [ 0.3586],\n",
      "        [-0.2498],\n",
      "        [-1.5062],\n",
      "        [-0.9303],\n",
      "        [ 0.6865],\n",
      "        [ 0.1795],\n",
      "        [-0.5622],\n",
      "        [ 0.0798],\n",
      "        [-2.9358],\n",
      "        [ 1.9594],\n",
      "        [ 1.7677],\n",
      "        [-6.2949],\n",
      "        [ 0.5589],\n",
      "        [ 1.1611],\n",
      "        [ 3.7939],\n",
      "        [ 0.4882],\n",
      "        [ 1.1853],\n",
      "        [ 3.9819],\n",
      "        [ 1.2820],\n",
      "        [ 1.9184],\n",
      "        [-0.9781],\n",
      "        [-0.3066],\n",
      "        [-0.1190],\n",
      "        [ 0.2744],\n",
      "        [-1.1097],\n",
      "        [ 0.1884],\n",
      "        [ 0.9510],\n",
      "        [ 1.4949],\n",
      "        [ 0.8969],\n",
      "        [-0.4745],\n",
      "        [ 0.6331],\n",
      "        [ 1.4048],\n",
      "        [-0.9241],\n",
      "        [ 1.1874],\n",
      "        [ 0.6775],\n",
      "        [ 0.3359],\n",
      "        [-0.4032],\n",
      "        [-0.8036],\n",
      "        [-1.0377],\n",
      "        [-2.5629],\n",
      "        [-0.9361],\n",
      "        [-0.4520],\n",
      "        [ 0.3551],\n",
      "        [-1.4850],\n",
      "        [ 3.0021],\n",
      "        [ 1.0341],\n",
      "        [ 2.7916],\n",
      "        [ 1.5847],\n",
      "        [-0.0979],\n",
      "        [ 1.5826],\n",
      "        [ 1.0130],\n",
      "        [ 0.0585],\n",
      "        [-1.4061],\n",
      "        [ 0.0736],\n",
      "        [ 1.9433],\n",
      "        [-0.2308],\n",
      "        [ 0.5463],\n",
      "        [-0.7768],\n",
      "        [ 1.1330],\n",
      "        [-2.9202],\n",
      "        [-1.5733],\n",
      "        [-3.0670],\n",
      "        [-0.6827],\n",
      "        [ 0.1011],\n",
      "        [-2.4837],\n",
      "        [ 2.1372],\n",
      "        [ 0.4342],\n",
      "        [ 0.4337],\n",
      "        [ 0.3208],\n",
      "        [-1.8581],\n",
      "        [-0.9409],\n",
      "        [-0.4740],\n",
      "        [ 2.7440],\n",
      "        [ 1.6645],\n",
      "        [-0.3517],\n",
      "        [ 2.0685],\n",
      "        [-0.0204],\n",
      "        [ 1.2148],\n",
      "        [ 2.4701],\n",
      "        [-1.6193],\n",
      "        [-0.1533],\n",
      "        [ 2.3678],\n",
      "        [ 2.4401],\n",
      "        [-2.3900],\n",
      "        [-2.5041],\n",
      "        [-1.3410],\n",
      "        [ 4.7128]], grad_fn=<ThSubBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(pred -torch_target)\n",
    "#print(torch_inputs.shape)\n",
    "#print(test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
