{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: tensor(591.7285, grad_fn=<MseLossBackward>)\n",
      "\n",
      "Trained-model loss:  tensor(3.5281, grad_fn=<MseLossBackward>)\n",
      "\n",
      "tensor([[27.0055],\n",
      "        [20.9796],\n",
      "        [33.0439],\n",
      "        [33.2849],\n",
      "        [21.6753],\n",
      "        [16.3507],\n",
      "        [18.9656],\n",
      "        [21.3509],\n",
      "        [22.0326],\n",
      "        [17.9980],\n",
      "        [21.9053],\n",
      "        [23.0596],\n",
      "        [17.6746],\n",
      "        [13.5814],\n",
      "        [16.5190],\n",
      "        [15.8767],\n",
      "        [14.6048],\n",
      "        [13.5731],\n",
      "        [13.1945],\n",
      "        [15.8695],\n",
      "        [12.9784],\n",
      "        [23.2420],\n",
      "        [28.2057],\n",
      "        [33.0397],\n",
      "        [24.0547],\n",
      "        [23.5968],\n",
      "        [19.9722],\n",
      "        [19.9329],\n",
      "        [20.9672],\n",
      "        [18.5896],\n",
      "        [19.3504],\n",
      "        [21.0404],\n",
      "        [20.1646],\n",
      "        [22.4492],\n",
      "        [18.4316],\n",
      "        [32.1939],\n",
      "        [24.4678],\n",
      "        [30.7374],\n",
      "        [24.2385],\n",
      "        [19.2237],\n",
      "        [15.9299],\n",
      "        [24.3174],\n",
      "        [30.3805],\n",
      "        [25.4755],\n",
      "        [19.5072],\n",
      "        [22.7246],\n",
      "        [21.1360],\n",
      "        [24.1167],\n",
      "        [24.0630],\n",
      "        [23.4584],\n",
      "        [24.6223],\n",
      "        [21.7582],\n",
      "        [20.4331],\n",
      "        [21.5902],\n",
      "        [24.5526],\n",
      "        [21.5873],\n",
      "        [22.8763],\n",
      "        [20.8801],\n",
      "        [24.2469],\n",
      "        [21.3668],\n",
      "        [20.9494],\n",
      "        [25.2162],\n",
      "        [27.6581],\n",
      "        [21.3582],\n",
      "        [25.3971],\n",
      "        [18.9928],\n",
      "        [20.2716],\n",
      "        [24.1366],\n",
      "        [24.9377],\n",
      "        [18.4114],\n",
      "        [20.2231],\n",
      "        [17.4242],\n",
      "        [19.5747],\n",
      "        [20.9511],\n",
      "        [18.7569],\n",
      "        [22.6818],\n",
      "        [21.2837],\n",
      "        [20.7207],\n",
      "        [21.2967],\n",
      "        [16.1756],\n",
      "        [19.6464],\n",
      "        [21.0244],\n",
      "        [19.4852],\n",
      "        [19.1855],\n",
      "        [17.4082],\n",
      "        [19.3288],\n",
      "        [16.1705],\n",
      "        [17.1301],\n",
      "        [18.5471],\n",
      "        [19.9518],\n",
      "        [17.5403],\n",
      "        [17.7047],\n",
      "        [16.8232],\n",
      "        [18.8549],\n",
      "        [15.4915],\n",
      "        [17.3516],\n",
      "        [16.2041],\n",
      "        [14.5548],\n",
      "        [13.9793],\n",
      "        [15.7276],\n",
      "        [14.8547],\n",
      "        [13.6581],\n",
      "        [19.1146],\n",
      "        [20.6087],\n",
      "        [18.3144],\n",
      "        [12.7795],\n",
      "        [24.3257],\n",
      "        [24.8259],\n",
      "        [27.0571],\n",
      "        [46.8174],\n",
      "        [49.7103],\n",
      "        [21.1489],\n",
      "        [25.8317],\n",
      "        [46.3729],\n",
      "        [21.2337],\n",
      "        [20.4672],\n",
      "        [17.3185],\n",
      "        [19.6126],\n",
      "        [19.9135],\n",
      "        [24.5310],\n",
      "        [23.2724],\n",
      "        [29.3460],\n",
      "        [24.5503],\n",
      "        [26.1759],\n",
      "        [26.9127],\n",
      "        [39.1132],\n",
      "        [37.2031],\n",
      "        [34.4639],\n",
      "        [35.2501],\n",
      "        [32.6109],\n",
      "        [43.7786],\n",
      "        [31.2639],\n",
      "        [33.5065],\n",
      "        [33.2855],\n",
      "        [32.7879],\n",
      "        [35.8344],\n",
      "        [29.3043],\n",
      "        [27.7082],\n",
      "        [22.9157],\n",
      "        [31.5758],\n",
      "        [22.8157],\n",
      "        [42.7283],\n",
      "        [47.3964],\n",
      "        [23.1327],\n",
      "        [23.1263],\n",
      "        [21.5818],\n",
      "        [17.3362],\n",
      "        [23.9805],\n",
      "        [23.8370],\n",
      "        [23.9192],\n",
      "        [20.9876],\n",
      "        [28.4005],\n",
      "        [26.8959],\n",
      "        [42.8994],\n",
      "        [43.2229],\n",
      "        [41.0064],\n",
      "        [29.5414],\n",
      "        [33.2191],\n",
      "        [23.4932],\n",
      "        [42.6192],\n",
      "        [43.5656],\n",
      "        [29.1316],\n",
      "        [23.9468],\n",
      "        [27.5719],\n",
      "        [23.3823],\n",
      "        [21.2100],\n",
      "        [24.7884],\n",
      "        [16.8989],\n",
      "        [22.4013],\n",
      "        [21.5724],\n",
      "        [25.0684],\n",
      "        [25.2129],\n",
      "        [26.2444],\n",
      "        [36.9931],\n",
      "        [31.3394],\n",
      "        [40.5396],\n",
      "        [46.7430],\n",
      "        [30.9816],\n",
      "        [35.2248],\n",
      "        [25.2893],\n",
      "        [27.6261],\n",
      "        [41.1750],\n",
      "        [23.9112],\n",
      "        [22.5283],\n",
      "        [32.4231],\n",
      "        [30.6474],\n",
      "        [35.2126],\n",
      "        [34.5024],\n",
      "        [42.3129],\n",
      "        [48.6468],\n",
      "        [27.4794],\n",
      "        [24.9501],\n",
      "        [20.4941],\n",
      "        [23.1770],\n",
      "        [28.8036],\n",
      "        [26.4893],\n",
      "        [24.7562],\n",
      "        [25.2935],\n",
      "        [20.9286],\n",
      "        [24.0627],\n",
      "        [24.2330],\n",
      "        [31.8826],\n",
      "        [33.4047],\n",
      "        [27.8610],\n",
      "        [33.1753],\n",
      "        [24.7984],\n",
      "        [20.9065],\n",
      "        [18.3204],\n",
      "        [23.7167],\n",
      "        [19.0807],\n",
      "        [18.8556],\n",
      "        [17.2733],\n",
      "        [19.0466],\n",
      "        [22.5262],\n",
      "        [23.9925],\n",
      "        [23.4446],\n",
      "        [24.1047],\n",
      "        [22.0960],\n",
      "        [19.5870],\n",
      "        [18.7991],\n",
      "        [22.7275],\n",
      "        [21.4800],\n",
      "        [19.2639],\n",
      "        [20.3914],\n",
      "        [19.6874],\n",
      "        [20.6553],\n",
      "        [29.5272],\n",
      "        [20.0028],\n",
      "        [24.0364],\n",
      "        [29.0259],\n",
      "        [21.2059],\n",
      "        [25.3606],\n",
      "        [23.8560],\n",
      "        [19.3240],\n",
      "        [17.0112],\n",
      "        [20.8860],\n",
      "        [21.0233],\n",
      "        [20.3065],\n",
      "        [26.4713],\n",
      "        [21.4659],\n",
      "        [26.4756],\n",
      "        [22.0850],\n",
      "        [23.3767],\n",
      "        [49.6437],\n",
      "        [49.3406],\n",
      "        [48.3597],\n",
      "        [50.3586],\n",
      "        [13.5502],\n",
      "        [12.2938],\n",
      "        [12.9697],\n",
      "        [13.9865],\n",
      "        [11.4795],\n",
      "        [11.7378],\n",
      "        [ 8.8798],\n",
      "        [ 7.5642],\n",
      "        [ 9.3594],\n",
      "        [13.2677],\n",
      "        [16.9051],\n",
      "        [10.2589],\n",
      "        [13.8611],\n",
      "        [16.2939],\n",
      "        [ 5.4882],\n",
      "        [ 6.7853],\n",
      "        [11.1819],\n",
      "        [ 9.5820],\n",
      "        [29.8184],\n",
      "        [16.2219],\n",
      "        [15.9934],\n",
      "        [ 6.8810],\n",
      "        [ 7.4744],\n",
      "        [ 9.2903],\n",
      "        [ 8.9884],\n",
      "        [ 9.3510],\n",
      "        [13.1949],\n",
      "        [ 9.1969],\n",
      "        [10.4255],\n",
      "        [11.6331],\n",
      "        [10.9048],\n",
      "        [13.1759],\n",
      "        [17.2874],\n",
      "        [14.9775],\n",
      "        [12.0359],\n",
      "        [ 8.2968],\n",
      "        [11.9964],\n",
      "        [ 9.4623],\n",
      "        [14.5371],\n",
      "        [17.4639],\n",
      "        [14.9480],\n",
      "        [11.1551],\n",
      "        [10.3150],\n",
      "        [15.6021],\n",
      "        [15.1341],\n",
      "        [17.9916],\n",
      "        [17.6847],\n",
      "        [17.7021],\n",
      "        [15.6826],\n",
      "        [14.5130],\n",
      "        [14.9585],\n",
      "        [18.5939],\n",
      "        [16.4736],\n",
      "        [19.6433],\n",
      "        [19.2692],\n",
      "        [20.7463],\n",
      "        [20.6232],\n",
      "        [21.0330],\n",
      "        [16.0798],\n",
      "        [17.5267],\n",
      "        [16.0330],\n",
      "        [19.4173],\n",
      "        [19.7011],\n",
      "        [20.7163],\n",
      "        [15.9372],\n",
      "        [17.1343],\n",
      "        [12.4337],\n",
      "        [14.9208],\n",
      "        [19.5419],\n",
      "        [22.0591],\n",
      "        [23.2260],\n",
      "        [24.5440],\n",
      "        [22.2645],\n",
      "        [18.7483],\n",
      "        [22.6685],\n",
      "        [15.1796],\n",
      "        [ 9.3148],\n",
      "        [16.0701],\n",
      "        [18.4807],\n",
      "        [21.6467],\n",
      "        [20.6678],\n",
      "        [19.9401],\n",
      "        [20.0100],\n",
      "        [18.0959],\n",
      "        [22.5590],\n",
      "        [16.6128]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "#Variable declarations\n",
    "#training_dataset = '/home/basic/Documents/Machine-learning/Projects/Boston-Housing/train.csv'\n",
    "training_dataset = '/Users/anishkirloskar/Documents/Machine-learning/Projects/Boston-Housing/train.csv'\n",
    "df = pd.read_csv(training_dataset)\n",
    "dfh = df.head()\n",
    "target = df.iloc[:,14:15]\n",
    "inputs = df.iloc[:,1:14]\n",
    "\n",
    "#Test/inference dataset\n",
    "#test_dataset = '/home/basic/Documents/Machine-learning/Projects/Boston-Housing/test.csv'\n",
    "test_dataset = '/Users/anishkirloskar/Documents/Machine-learning/Projects/Boston-Housing/test.csv'\n",
    "df1 = pd.read_csv(test_dataset)\n",
    "df1h = df1.head()\n",
    "test_inputs = df1.iloc[:,1:14]\n",
    "\n",
    "#Convert df to tensors\n",
    "torch_target = torch.Tensor(target.values)\n",
    "torch_inputs = torch.Tensor(inputs.values)\n",
    "test_inputs = torch.Tensor(test_inputs.values)\n",
    "\n",
    "#Define dataset\n",
    "train_ds = TensorDataset(torch_inputs,torch_target)\n",
    "\n",
    "#Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds,batch_size,shuffle=True)\n",
    "\n",
    "loss_fn = F.mse_loss\n",
    "pred = torch.Tensor()\n",
    "#loss = loss_fn(model(torch_inputs),torch_target)\n",
    "\n",
    "#Create a function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xi,yi in train_dl:\n",
    "            pred = model(xi)\n",
    "            loss = loss_fn(pred,yi)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    \n",
    "    print('Trained-model loss: ',loss_fn(model(torch_inputs),torch_target))\n",
    "    #preds = model(torch_inputs)\n",
    "    #print(\"Predictions:\",preds)\n",
    "    #print(\"Targets:\",torch_target)\n",
    "    print('')\n",
    "\n",
    "#Define model\n",
    "class NeuralN1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(13,75)\n",
    "        self.linear2 = nn.Linear(75,50)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(50,25)\n",
    "        #self.act2 = nn.ReLU()\n",
    "        self.linear4 = nn.Linear(25,12)\n",
    "        self.linear5 = nn.Linear(12,5)\n",
    "        self.linear6 = nn.Linear(5,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.act1(self.linear1(x))\n",
    "        x = self.act1(self.linear2(x))\n",
    "        #x = self.act1(x)\n",
    "        x = self.act1(self.linear3(x))\n",
    "        #x = self.act2(x)\n",
    "        x = self.act1(self.linear4(x))\n",
    "        x = self.act1(self.linear5(x))\n",
    "        x = self.linear6(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralN1()\n",
    "loss = loss_fn(model(torch_inputs),torch_target)\n",
    "print('Initial loss:', loss)\n",
    "print('')\n",
    "opt1 = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "opt2 = torch.optim.Adagrad(model.parameters(), lr = 1e-5)\n",
    "\n",
    "fit(700,model,loss_fn,opt1)\n",
    "pred = model(torch_inputs)\n",
    "print(pred)\n",
    "#fit(100,model,loss_fn,opt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0055],\n",
      "        [-0.6204],\n",
      "        [-0.3561],\n",
      "        [-2.9151],\n",
      "        [-1.2247],\n",
      "        [ 1.3507],\n",
      "        [ 0.0656],\n",
      "        [-0.3491],\n",
      "        [ 1.6326],\n",
      "        [-0.2020],\n",
      "        [ 2.0053],\n",
      "        [-0.0404],\n",
      "        [-2.5254],\n",
      "        [-0.0186],\n",
      "        [-3.0810],\n",
      "        [ 0.6767],\n",
      "        [ 0.1048],\n",
      "        [-1.2269],\n",
      "        [ 0.4945],\n",
      "        [ 1.3695],\n",
      "        [-0.5216],\n",
      "        [-1.4580],\n",
      "        [-2.5943],\n",
      "        [-1.8603],\n",
      "        [-1.2453],\n",
      "        [-1.1032],\n",
      "        [-1.2278],\n",
      "        [ 0.6329],\n",
      "        [ 0.9672],\n",
      "        [ 1.9896],\n",
      "        [-0.0496],\n",
      "        [ 1.3404],\n",
      "        [-0.3354],\n",
      "        [-0.9508],\n",
      "        [-0.4684],\n",
      "        [-3.2061],\n",
      "        [-0.2322],\n",
      "        [-0.8626],\n",
      "        [ 0.9385],\n",
      "        [ 0.5237],\n",
      "        [-0.0701],\n",
      "        [-0.6826],\n",
      "        [-2.6195],\n",
      "        [ 1.9755],\n",
      "        [ 0.1072],\n",
      "        [ 0.7246],\n",
      "        [ 3.7360],\n",
      "        [-0.0833],\n",
      "        [ 1.2630],\n",
      "        [ 0.0584],\n",
      "        [ 0.5223],\n",
      "        [ 0.3582],\n",
      "        [ 0.4331],\n",
      "        [ 0.7902],\n",
      "        [-3.4474],\n",
      "        [-2.3127],\n",
      "        [-0.0237],\n",
      "        [-3.0198],\n",
      "        [-2.3531],\n",
      "        [-1.1332],\n",
      "        [-1.2506],\n",
      "        [ 1.6161],\n",
      "        [-1.0419],\n",
      "        [-1.2418],\n",
      "        [ 0.3971],\n",
      "        [-1.6072],\n",
      "        [-1.1284],\n",
      "        [-3.3634],\n",
      "        [-1.5623],\n",
      "        [-0.1886],\n",
      "        [ 0.9231],\n",
      "        [-2.0758],\n",
      "        [-0.8253],\n",
      "        [ 1.1511],\n",
      "        [-0.6431],\n",
      "        [-0.1182],\n",
      "        [ 2.7837],\n",
      "        [-0.4793],\n",
      "        [ 2.0967],\n",
      "        [-4.2244],\n",
      "        [ 0.3464],\n",
      "        [-0.9756],\n",
      "        [-0.8148],\n",
      "        [-1.3145],\n",
      "        [ 0.1082],\n",
      "        [ 0.5288],\n",
      "        [ 0.4705],\n",
      "        [ 0.9301],\n",
      "        [ 0.5471],\n",
      "        [ 0.3518],\n",
      "        [-0.8597],\n",
      "        [ 2.1047],\n",
      "        [-0.5768],\n",
      "        [ 1.7549],\n",
      "        [ 2.1915],\n",
      "        [-0.4484],\n",
      "        [ 1.8041],\n",
      "        [ 1.1548],\n",
      "        [ 0.1793],\n",
      "        [ 1.1276],\n",
      "        [-2.9453],\n",
      "        [-1.7419],\n",
      "        [-2.3854],\n",
      "        [ 1.2087],\n",
      "        [ 1.3144],\n",
      "        [-0.3205],\n",
      "        [ 0.0257],\n",
      "        [ 1.5259],\n",
      "        [ 0.0571],\n",
      "        [-3.1826],\n",
      "        [-0.2897],\n",
      "        [-1.5511],\n",
      "        [ 0.8317],\n",
      "        [-3.6271],\n",
      "        [-2.5663],\n",
      "        [-1.8328],\n",
      "        [-0.0815],\n",
      "        [ 0.5126],\n",
      "        [-3.1865],\n",
      "        [ 0.9310],\n",
      "        [ 0.6724],\n",
      "        [-0.0540],\n",
      "        [ 1.3503],\n",
      "        [ 1.5759],\n",
      "        [-2.9873],\n",
      "        [ 1.9132],\n",
      "        [-2.5969],\n",
      "        [-1.7361],\n",
      "        [-2.6499],\n",
      "        [ 0.1109],\n",
      "        [-6.2214],\n",
      "        [-0.7361],\n",
      "        [-1.3935],\n",
      "        [-3.7145],\n",
      "        [ 2.2879],\n",
      "        [-0.5656],\n",
      "        [-1.7957],\n",
      "        [-1.3918],\n",
      "        [-7.3843],\n",
      "        [-1.3242],\n",
      "        [-1.2843],\n",
      "        [-5.7717],\n",
      "        [-2.6036],\n",
      "        [ 0.5327],\n",
      "        [-1.2737],\n",
      "        [-2.8182],\n",
      "        [-1.9638],\n",
      "        [-4.1195],\n",
      "        [ 0.1370],\n",
      "        [ 0.6192],\n",
      "        [-0.7124],\n",
      "        [ 0.9005],\n",
      "        [-3.2041],\n",
      "        [-1.9006],\n",
      "        [-6.7771],\n",
      "        [ 3.4064],\n",
      "        [-2.0586],\n",
      "        [ 1.7191],\n",
      "        [-0.8068],\n",
      "        [ 0.9192],\n",
      "        [-4.7344],\n",
      "        [ 0.1316],\n",
      "        [-0.0532],\n",
      "        [ 2.4719],\n",
      "        [ 1.3823],\n",
      "        [-0.9900],\n",
      "        [ 1.0884],\n",
      "        [-0.7011],\n",
      "        [-1.8987],\n",
      "        [-2.9276],\n",
      "        [-1.1316],\n",
      "        [ 0.8129],\n",
      "        [ 1.4444],\n",
      "        [-5.8069],\n",
      "        [-2.4606],\n",
      "        [-2.5604],\n",
      "        [-2.0570],\n",
      "        [-0.0184],\n",
      "        [-1.2752],\n",
      "        [ 2.4893],\n",
      "        [-3.0739],\n",
      "        [-2.3250],\n",
      "        [-1.2888],\n",
      "        [-1.8717],\n",
      "        [-2.7769],\n",
      "        [-1.7526],\n",
      "        [ 0.1126],\n",
      "        [-0.8976],\n",
      "        [-3.6871],\n",
      "        [-1.3532],\n",
      "        [-4.7206],\n",
      "        [ 2.9501],\n",
      "        [ 0.3941],\n",
      "        [ 0.8770],\n",
      "        [ 0.3036],\n",
      "        [-1.4107],\n",
      "        [ 0.8562],\n",
      "        [-1.8065],\n",
      "        [ 0.6286],\n",
      "        [ 2.0627],\n",
      "        [-2.1670],\n",
      "        [-1.2174],\n",
      "        [-2.6953],\n",
      "        [-0.5390],\n",
      "        [-0.2248],\n",
      "        [ 1.9984],\n",
      "        [ 0.6065],\n",
      "        [ 2.2204],\n",
      "        [ 1.6167],\n",
      "        [-0.3193],\n",
      "        [ 2.6556],\n",
      "        [-0.5267],\n",
      "        [-0.7534],\n",
      "        [-0.5738],\n",
      "        [ 0.1925],\n",
      "        [-1.5554],\n",
      "        [-0.4953],\n",
      "        [-0.1040],\n",
      "        [ 0.2870],\n",
      "        [-1.0009],\n",
      "        [ 0.5275],\n",
      "        [ 0.7800],\n",
      "        [-0.2361],\n",
      "        [-0.2086],\n",
      "        [ 0.6874],\n",
      "        [ 1.9553],\n",
      "        [-3.1728],\n",
      "        [ 3.5028],\n",
      "        [ 0.1364],\n",
      "        [-2.1741],\n",
      "        [-1.8941],\n",
      "        [ 0.8606],\n",
      "        [-2.7440],\n",
      "        [ 0.7240],\n",
      "        [-0.7888],\n",
      "        [-0.8140],\n",
      "        [-1.6767],\n",
      "        [-2.2935],\n",
      "        [ 1.4713],\n",
      "        [ 0.6659],\n",
      "        [-1.0244],\n",
      "        [ 0.1850],\n",
      "        [ 0.2767],\n",
      "        [-0.3563],\n",
      "        [-0.6594],\n",
      "        [-1.6403],\n",
      "        [ 0.3586],\n",
      "        [-0.2498],\n",
      "        [-1.5062],\n",
      "        [-0.9303],\n",
      "        [ 0.6865],\n",
      "        [ 0.1795],\n",
      "        [-0.5622],\n",
      "        [ 0.0798],\n",
      "        [-2.9358],\n",
      "        [ 1.9594],\n",
      "        [ 1.7677],\n",
      "        [-6.2949],\n",
      "        [ 0.5589],\n",
      "        [ 1.1611],\n",
      "        [ 3.7939],\n",
      "        [ 0.4882],\n",
      "        [ 1.1853],\n",
      "        [ 3.9819],\n",
      "        [ 1.2820],\n",
      "        [ 1.9184],\n",
      "        [-0.9781],\n",
      "        [-0.3066],\n",
      "        [-0.1190],\n",
      "        [ 0.2744],\n",
      "        [-1.1097],\n",
      "        [ 0.1884],\n",
      "        [ 0.9510],\n",
      "        [ 1.4949],\n",
      "        [ 0.8969],\n",
      "        [-0.4745],\n",
      "        [ 0.6331],\n",
      "        [ 1.4048],\n",
      "        [-0.9241],\n",
      "        [ 1.1874],\n",
      "        [ 0.6775],\n",
      "        [ 0.3359],\n",
      "        [-0.4032],\n",
      "        [-0.8036],\n",
      "        [-1.0377],\n",
      "        [-2.5629],\n",
      "        [-0.9361],\n",
      "        [-0.4520],\n",
      "        [ 0.3551],\n",
      "        [-1.4850],\n",
      "        [ 3.0021],\n",
      "        [ 1.0341],\n",
      "        [ 2.7916],\n",
      "        [ 1.5847],\n",
      "        [-0.0979],\n",
      "        [ 1.5826],\n",
      "        [ 1.0130],\n",
      "        [ 0.0585],\n",
      "        [-1.4061],\n",
      "        [ 0.0736],\n",
      "        [ 1.9433],\n",
      "        [-0.2308],\n",
      "        [ 0.5463],\n",
      "        [-0.7768],\n",
      "        [ 1.1330],\n",
      "        [-2.9202],\n",
      "        [-1.5733],\n",
      "        [-3.0670],\n",
      "        [-0.6827],\n",
      "        [ 0.1011],\n",
      "        [-2.4837],\n",
      "        [ 2.1372],\n",
      "        [ 0.4342],\n",
      "        [ 0.4337],\n",
      "        [ 0.3208],\n",
      "        [-1.8581],\n",
      "        [-0.9409],\n",
      "        [-0.4740],\n",
      "        [ 2.7440],\n",
      "        [ 1.6645],\n",
      "        [-0.3517],\n",
      "        [ 2.0685],\n",
      "        [-0.0204],\n",
      "        [ 1.2148],\n",
      "        [ 2.4701],\n",
      "        [-1.6193],\n",
      "        [-0.1533],\n",
      "        [ 2.3678],\n",
      "        [ 2.4401],\n",
      "        [-2.3900],\n",
      "        [-2.5041],\n",
      "        [-1.3410],\n",
      "        [ 4.7128]], grad_fn=<ThSubBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(pred -torch_target)\n",
    "#print(torch_inputs.shape)\n",
    "#print(test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
