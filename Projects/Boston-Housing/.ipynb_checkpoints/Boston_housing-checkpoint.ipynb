{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: tensor(596.1689, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "Epoch [10/700], Loss: 1.3263\n",
      "Epoch [20/700], Loss: 12.3346\n",
      "Epoch [30/700], Loss: 29.6245\n",
      "Epoch [40/700], Loss: 43.8250\n",
      "Epoch [50/700], Loss: 7.6599\n",
      "Epoch [60/700], Loss: 96.8811\n",
      "Epoch [70/700], Loss: 1.8838\n",
      "Epoch [80/700], Loss: 59.0974\n",
      "Epoch [90/700], Loss: 4.5674\n",
      "Epoch [100/700], Loss: 7.2483\n",
      "Epoch [110/700], Loss: 36.7170\n",
      "Epoch [120/700], Loss: 4.1469\n",
      "Epoch [130/700], Loss: 1.8080\n",
      "Epoch [140/700], Loss: 1.9290\n",
      "Epoch [150/700], Loss: 2.8642\n",
      "Epoch [160/700], Loss: 3.6323\n",
      "Epoch [170/700], Loss: 17.6995\n",
      "Epoch [180/700], Loss: 4.0810\n",
      "Epoch [190/700], Loss: 6.9725\n",
      "Epoch [200/700], Loss: 6.7090\n",
      "Epoch [210/700], Loss: 1.9785\n",
      "Epoch [220/700], Loss: 19.8843\n",
      "Epoch [230/700], Loss: 3.9650\n",
      "Epoch [240/700], Loss: 0.9337\n",
      "Epoch [250/700], Loss: 16.5233\n",
      "Epoch [260/700], Loss: 11.6505\n",
      "Epoch [270/700], Loss: 10.1156\n",
      "Epoch [280/700], Loss: 3.1149\n",
      "Epoch [290/700], Loss: 1.2161\n",
      "Epoch [300/700], Loss: 17.9381\n",
      "Epoch [310/700], Loss: 7.1356\n",
      "Epoch [320/700], Loss: 57.5535\n",
      "Epoch [330/700], Loss: 4.5372\n",
      "Epoch [340/700], Loss: 8.5425\n",
      "Epoch [350/700], Loss: 6.4356\n",
      "Epoch [360/700], Loss: 3.1312\n",
      "Epoch [370/700], Loss: 3.1508\n",
      "Epoch [380/700], Loss: 1.3990\n",
      "Epoch [390/700], Loss: 7.1697\n",
      "Epoch [400/700], Loss: 10.2805\n",
      "Epoch [410/700], Loss: 30.9823\n",
      "Epoch [420/700], Loss: 2.7251\n",
      "Epoch [430/700], Loss: 2.1005\n",
      "Epoch [440/700], Loss: 3.9653\n",
      "Epoch [450/700], Loss: 4.0589\n",
      "Epoch [460/700], Loss: 24.2019\n",
      "Epoch [470/700], Loss: 0.1849\n",
      "Epoch [480/700], Loss: 0.7646\n",
      "Epoch [490/700], Loss: 5.0863\n",
      "Epoch [500/700], Loss: 0.9474\n",
      "Epoch [510/700], Loss: 0.9319\n",
      "Epoch [520/700], Loss: 2.6706\n",
      "Epoch [530/700], Loss: 2.5161\n",
      "Epoch [540/700], Loss: 1.7095\n",
      "Epoch [550/700], Loss: 0.1824\n",
      "Epoch [560/700], Loss: 5.2924\n",
      "Epoch [570/700], Loss: 28.4056\n",
      "Epoch [580/700], Loss: 11.6296\n",
      "Epoch [590/700], Loss: 0.9925\n",
      "Epoch [600/700], Loss: 10.9427\n",
      "Epoch [610/700], Loss: 2.0116\n",
      "Epoch [620/700], Loss: 2.4093\n",
      "Epoch [630/700], Loss: 2.0843\n",
      "Epoch [640/700], Loss: 1.6338\n",
      "Epoch [650/700], Loss: 4.3462\n",
      "Epoch [660/700], Loss: 14.6239\n",
      "Epoch [670/700], Loss: 2.5801\n",
      "Epoch [680/700], Loss: 7.4154\n",
      "Epoch [690/700], Loss: 3.6393\n",
      "Epoch [700/700], Loss: 0.7545\n",
      "Trained-model loss:  tensor(2.5777, grad_fn=<MseLossBackward0>)\n",
      "Predictions: tensor([[27.6287],\n",
      "        [21.2620],\n",
      "        [34.9688],\n",
      "        [33.8327],\n",
      "        [20.7436],\n",
      "        [16.4175],\n",
      "        [19.6572],\n",
      "        [21.0633],\n",
      "        [20.6518],\n",
      "        [18.5452],\n",
      "        [20.6000],\n",
      "        [21.7263],\n",
      "        [16.5222],\n",
      "        [13.4916],\n",
      "        [17.5535],\n",
      "        [16.9637],\n",
      "        [14.9171],\n",
      "        [13.6757],\n",
      "        [13.1510],\n",
      "        [15.2442],\n",
      "        [13.3815],\n",
      "        [22.6351],\n",
      "        [29.5495],\n",
      "        [33.9218],\n",
      "        [24.6641],\n",
      "        [24.7268],\n",
      "        [21.0685],\n",
      "        [20.6347],\n",
      "        [21.4377],\n",
      "        [18.0547],\n",
      "        [18.6908],\n",
      "        [20.2596],\n",
      "        [21.9913],\n",
      "        [23.6360],\n",
      "        [18.4684],\n",
      "        [35.4175],\n",
      "        [24.3560],\n",
      "        [33.2730],\n",
      "        [23.4463],\n",
      "        [17.9339],\n",
      "        [17.2793],\n",
      "        [23.3109],\n",
      "        [33.0374],\n",
      "        [25.5737],\n",
      "        [21.8571],\n",
      "        [22.2041],\n",
      "        [19.9843],\n",
      "        [23.8470],\n",
      "        [23.3577],\n",
      "        [22.8452],\n",
      "        [25.0702],\n",
      "        [21.0768],\n",
      "        [19.6165],\n",
      "        [20.6421],\n",
      "        [26.7975],\n",
      "        [23.3818],\n",
      "        [22.4599],\n",
      "        [22.6762],\n",
      "        [24.8345],\n",
      "        [21.3960],\n",
      "        [22.0212],\n",
      "        [26.1090],\n",
      "        [28.8082],\n",
      "        [23.3806],\n",
      "        [24.0497],\n",
      "        [19.5113],\n",
      "        [21.0640],\n",
      "        [23.7988],\n",
      "        [25.4788],\n",
      "        [19.0005],\n",
      "        [20.2701],\n",
      "        [17.5951],\n",
      "        [19.8900],\n",
      "        [20.6147],\n",
      "        [19.0079],\n",
      "        [22.5514],\n",
      "        [21.5000],\n",
      "        [19.7876],\n",
      "        [20.6472],\n",
      "        [16.6751],\n",
      "        [18.6505],\n",
      "        [21.6147],\n",
      "        [20.2914],\n",
      "        [19.3346],\n",
      "        [16.9153],\n",
      "        [19.3499],\n",
      "        [15.9221],\n",
      "        [16.8085],\n",
      "        [18.7435],\n",
      "        [20.6442],\n",
      "        [17.3155],\n",
      "        [16.9240],\n",
      "        [16.7500],\n",
      "        [19.2978],\n",
      "        [15.7779],\n",
      "        [17.1046],\n",
      "        [13.8131],\n",
      "        [14.3243],\n",
      "        [13.4712],\n",
      "        [13.5998],\n",
      "        [15.4132],\n",
      "        [15.2866],\n",
      "        [19.5741],\n",
      "        [18.4862],\n",
      "        [18.1272],\n",
      "        [13.7578],\n",
      "        [25.4972],\n",
      "        [25.8905],\n",
      "        [29.2626],\n",
      "        [51.2618],\n",
      "        [53.4329],\n",
      "        [21.6033],\n",
      "        [25.8186],\n",
      "        [49.5844],\n",
      "        [22.7575],\n",
      "        [20.8644],\n",
      "        [17.6826],\n",
      "        [19.4569],\n",
      "        [20.3125],\n",
      "        [25.1584],\n",
      "        [23.5131],\n",
      "        [29.1434],\n",
      "        [23.6520],\n",
      "        [27.1736],\n",
      "        [28.9090],\n",
      "        [41.8550],\n",
      "        [39.3804],\n",
      "        [35.3822],\n",
      "        [38.9194],\n",
      "        [34.8341],\n",
      "        [46.5005],\n",
      "        [32.1399],\n",
      "        [35.3203],\n",
      "        [34.9105],\n",
      "        [33.5139],\n",
      "        [38.1000],\n",
      "        [30.9867],\n",
      "        [28.3624],\n",
      "        [27.1143],\n",
      "        [33.6761],\n",
      "        [25.0100],\n",
      "        [49.5860],\n",
      "        [52.0958],\n",
      "        [23.0943],\n",
      "        [22.4810],\n",
      "        [23.2113],\n",
      "        [19.1368],\n",
      "        [24.1786],\n",
      "        [22.8951],\n",
      "        [24.6019],\n",
      "        [20.9853],\n",
      "        [28.6539],\n",
      "        [27.9240],\n",
      "        [46.5722],\n",
      "        [47.6699],\n",
      "        [42.6000],\n",
      "        [34.0911],\n",
      "        [33.2344],\n",
      "        [23.5928],\n",
      "        [46.0358],\n",
      "        [48.2874],\n",
      "        [29.1954],\n",
      "        [24.3144],\n",
      "        [27.5276],\n",
      "        [23.1814],\n",
      "        [20.7481],\n",
      "        [27.1216],\n",
      "        [17.3213],\n",
      "        [22.3487],\n",
      "        [22.5605],\n",
      "        [26.4395],\n",
      "        [26.0685],\n",
      "        [29.6879],\n",
      "        [40.2066],\n",
      "        [33.3151],\n",
      "        [41.8248],\n",
      "        [50.1253],\n",
      "        [32.7227],\n",
      "        [38.1556],\n",
      "        [23.4666],\n",
      "        [28.4844],\n",
      "        [45.4650],\n",
      "        [26.0546],\n",
      "        [25.8085],\n",
      "        [35.1926],\n",
      "        [32.0633],\n",
      "        [36.0587],\n",
      "        [36.3768],\n",
      "        [44.8485],\n",
      "        [52.1080],\n",
      "        [29.4154],\n",
      "        [23.8396],\n",
      "        [20.3878],\n",
      "        [22.8105],\n",
      "        [30.8300],\n",
      "        [29.1522],\n",
      "        [23.9436],\n",
      "        [24.8744],\n",
      "        [21.4763],\n",
      "        [24.6422],\n",
      "        [25.7537],\n",
      "        [33.7830],\n",
      "        [32.9045],\n",
      "        [28.4366],\n",
      "        [34.9619],\n",
      "        [26.0540],\n",
      "        [20.5215],\n",
      "        [17.8733],\n",
      "        [24.4595],\n",
      "        [18.7858],\n",
      "        [19.4392],\n",
      "        [18.5449],\n",
      "        [20.2874],\n",
      "        [22.4740],\n",
      "        [24.0467],\n",
      "        [24.8660],\n",
      "        [25.0109],\n",
      "        [22.5471],\n",
      "        [18.9618],\n",
      "        [18.8910],\n",
      "        [23.0638],\n",
      "        [22.3967],\n",
      "        [19.8654],\n",
      "        [21.8116],\n",
      "        [20.5670],\n",
      "        [20.6108],\n",
      "        [29.5974],\n",
      "        [19.0545],\n",
      "        [25.3740],\n",
      "        [30.9433],\n",
      "        [23.8275],\n",
      "        [25.5599],\n",
      "        [25.1514],\n",
      "        [20.2657],\n",
      "        [16.8634],\n",
      "        [20.8679],\n",
      "        [22.2295],\n",
      "        [21.6163],\n",
      "        [26.5075],\n",
      "        [22.9387],\n",
      "        [26.9450],\n",
      "        [22.8468],\n",
      "        [24.6308],\n",
      "        [50.2765],\n",
      "        [50.5827],\n",
      "        [50.9134],\n",
      "        [52.3836],\n",
      "        [13.0647],\n",
      "        [12.6168],\n",
      "        [13.1137],\n",
      "        [12.8054],\n",
      "        [11.2313],\n",
      "        [11.2873],\n",
      "        [ 9.4661],\n",
      "        [ 6.1480],\n",
      "        [ 6.4837],\n",
      "        [12.7373],\n",
      "        [18.9082],\n",
      "        [ 9.9063],\n",
      "        [14.6683],\n",
      "        [15.4629],\n",
      "        [ 4.9616],\n",
      "        [ 5.6711],\n",
      "        [10.5525],\n",
      "        [ 8.1725],\n",
      "        [30.4115],\n",
      "        [16.5349],\n",
      "        [17.1321],\n",
      "        [ 7.2253],\n",
      "        [ 8.0430],\n",
      "        [10.5932],\n",
      "        [ 8.6828],\n",
      "        [ 9.4627],\n",
      "        [11.7602],\n",
      "        [ 9.1528],\n",
      "        [11.1258],\n",
      "        [11.9047],\n",
      "        [11.6957],\n",
      "        [13.5071],\n",
      "        [16.2230],\n",
      "        [14.6381],\n",
      "        [13.7728],\n",
      "        [ 8.8358],\n",
      "        [12.8652],\n",
      "        [ 8.3998],\n",
      "        [13.9810],\n",
      "        [16.3336],\n",
      "        [13.6484],\n",
      "        [11.9603],\n",
      "        [12.0348],\n",
      "        [15.6986],\n",
      "        [14.0865],\n",
      "        [18.0367],\n",
      "        [17.6476],\n",
      "        [17.7929],\n",
      "        [15.2726],\n",
      "        [13.4284],\n",
      "        [16.4723],\n",
      "        [19.3811],\n",
      "        [16.9055],\n",
      "        [19.6904],\n",
      "        [20.2838],\n",
      "        [21.8650],\n",
      "        [21.1179],\n",
      "        [21.0872],\n",
      "        [16.6201],\n",
      "        [17.3250],\n",
      "        [18.7036],\n",
      "        [20.0977],\n",
      "        [20.2874],\n",
      "        [20.8624],\n",
      "        [16.8558],\n",
      "        [16.3582],\n",
      "        [11.9154],\n",
      "        [15.0566],\n",
      "        [22.6545],\n",
      "        [22.3511],\n",
      "        [24.5951],\n",
      "        [21.1899],\n",
      "        [20.3885],\n",
      "        [20.0101],\n",
      "        [21.6313],\n",
      "        [14.9217],\n",
      "        [ 8.0101],\n",
      "        [14.0633],\n",
      "        [19.1135],\n",
      "        [20.4693],\n",
      "        [19.9185],\n",
      "        [19.1612],\n",
      "        [20.7104],\n",
      "        [18.1131],\n",
      "        [25.0190],\n",
      "        [16.9158]], grad_fn=<AddmmBackward0>)\n",
      "Targets: tensor([[24.0000],\n",
      "        [21.6000],\n",
      "        [33.4000],\n",
      "        [36.2000],\n",
      "        [22.9000],\n",
      "        [15.0000],\n",
      "        [18.9000],\n",
      "        [21.7000],\n",
      "        [20.4000],\n",
      "        [18.2000],\n",
      "        [19.9000],\n",
      "        [23.1000],\n",
      "        [20.2000],\n",
      "        [13.6000],\n",
      "        [19.6000],\n",
      "        [15.2000],\n",
      "        [14.5000],\n",
      "        [14.8000],\n",
      "        [12.7000],\n",
      "        [14.5000],\n",
      "        [13.5000],\n",
      "        [24.7000],\n",
      "        [30.8000],\n",
      "        [34.9000],\n",
      "        [25.3000],\n",
      "        [24.7000],\n",
      "        [21.2000],\n",
      "        [19.3000],\n",
      "        [20.0000],\n",
      "        [16.6000],\n",
      "        [19.4000],\n",
      "        [19.7000],\n",
      "        [20.5000],\n",
      "        [23.4000],\n",
      "        [18.9000],\n",
      "        [35.4000],\n",
      "        [24.7000],\n",
      "        [31.6000],\n",
      "        [23.3000],\n",
      "        [18.7000],\n",
      "        [16.0000],\n",
      "        [25.0000],\n",
      "        [33.0000],\n",
      "        [23.5000],\n",
      "        [19.4000],\n",
      "        [22.0000],\n",
      "        [17.4000],\n",
      "        [24.2000],\n",
      "        [22.8000],\n",
      "        [23.4000],\n",
      "        [24.1000],\n",
      "        [21.4000],\n",
      "        [20.0000],\n",
      "        [20.8000],\n",
      "        [28.0000],\n",
      "        [23.9000],\n",
      "        [22.9000],\n",
      "        [23.9000],\n",
      "        [26.6000],\n",
      "        [22.5000],\n",
      "        [22.2000],\n",
      "        [23.6000],\n",
      "        [28.7000],\n",
      "        [22.6000],\n",
      "        [25.0000],\n",
      "        [20.6000],\n",
      "        [21.4000],\n",
      "        [27.5000],\n",
      "        [26.5000],\n",
      "        [18.6000],\n",
      "        [19.3000],\n",
      "        [19.5000],\n",
      "        [20.4000],\n",
      "        [19.8000],\n",
      "        [19.4000],\n",
      "        [22.8000],\n",
      "        [18.5000],\n",
      "        [21.2000],\n",
      "        [19.2000],\n",
      "        [20.4000],\n",
      "        [19.3000],\n",
      "        [22.0000],\n",
      "        [20.3000],\n",
      "        [20.5000],\n",
      "        [17.3000],\n",
      "        [18.8000],\n",
      "        [15.7000],\n",
      "        [16.2000],\n",
      "        [18.0000],\n",
      "        [19.6000],\n",
      "        [18.4000],\n",
      "        [15.6000],\n",
      "        [17.4000],\n",
      "        [17.1000],\n",
      "        [13.3000],\n",
      "        [17.8000],\n",
      "        [14.4000],\n",
      "        [13.4000],\n",
      "        [13.8000],\n",
      "        [14.6000],\n",
      "        [17.8000],\n",
      "        [15.4000],\n",
      "        [21.5000],\n",
      "        [19.4000],\n",
      "        [17.0000],\n",
      "        [13.1000],\n",
      "        [24.3000],\n",
      "        [23.3000],\n",
      "        [27.0000],\n",
      "        [50.0000],\n",
      "        [50.0000],\n",
      "        [22.7000],\n",
      "        [25.0000],\n",
      "        [50.0000],\n",
      "        [23.8000],\n",
      "        [22.3000],\n",
      "        [17.4000],\n",
      "        [19.1000],\n",
      "        [23.1000],\n",
      "        [23.6000],\n",
      "        [22.6000],\n",
      "        [29.4000],\n",
      "        [23.2000],\n",
      "        [24.6000],\n",
      "        [29.9000],\n",
      "        [37.2000],\n",
      "        [39.8000],\n",
      "        [36.2000],\n",
      "        [37.9000],\n",
      "        [32.5000],\n",
      "        [50.0000],\n",
      "        [32.0000],\n",
      "        [34.9000],\n",
      "        [37.0000],\n",
      "        [30.5000],\n",
      "        [36.4000],\n",
      "        [31.1000],\n",
      "        [29.1000],\n",
      "        [30.3000],\n",
      "        [32.9000],\n",
      "        [24.1000],\n",
      "        [48.5000],\n",
      "        [50.0000],\n",
      "        [22.6000],\n",
      "        [24.4000],\n",
      "        [24.4000],\n",
      "        [19.3000],\n",
      "        [28.1000],\n",
      "        [23.7000],\n",
      "        [23.3000],\n",
      "        [21.7000],\n",
      "        [27.5000],\n",
      "        [30.1000],\n",
      "        [44.8000],\n",
      "        [50.0000],\n",
      "        [37.6000],\n",
      "        [31.6000],\n",
      "        [31.5000],\n",
      "        [24.3000],\n",
      "        [41.7000],\n",
      "        [48.3000],\n",
      "        [29.0000],\n",
      "        [24.0000],\n",
      "        [25.1000],\n",
      "        [22.0000],\n",
      "        [22.2000],\n",
      "        [23.7000],\n",
      "        [17.6000],\n",
      "        [24.3000],\n",
      "        [24.5000],\n",
      "        [26.2000],\n",
      "        [24.4000],\n",
      "        [24.8000],\n",
      "        [42.8000],\n",
      "        [33.8000],\n",
      "        [43.1000],\n",
      "        [48.8000],\n",
      "        [31.0000],\n",
      "        [36.5000],\n",
      "        [22.8000],\n",
      "        [30.7000],\n",
      "        [43.5000],\n",
      "        [25.2000],\n",
      "        [24.4000],\n",
      "        [35.2000],\n",
      "        [32.4000],\n",
      "        [35.1000],\n",
      "        [35.4000],\n",
      "        [46.0000],\n",
      "        [50.0000],\n",
      "        [32.2000],\n",
      "        [22.0000],\n",
      "        [20.1000],\n",
      "        [22.3000],\n",
      "        [28.5000],\n",
      "        [27.9000],\n",
      "        [23.9000],\n",
      "        [27.1000],\n",
      "        [20.3000],\n",
      "        [22.0000],\n",
      "        [26.4000],\n",
      "        [33.1000],\n",
      "        [36.1000],\n",
      "        [28.4000],\n",
      "        [33.4000],\n",
      "        [22.8000],\n",
      "        [20.3000],\n",
      "        [16.1000],\n",
      "        [22.1000],\n",
      "        [19.4000],\n",
      "        [16.2000],\n",
      "        [17.8000],\n",
      "        [19.8000],\n",
      "        [23.1000],\n",
      "        [23.8000],\n",
      "        [25.0000],\n",
      "        [24.6000],\n",
      "        [22.2000],\n",
      "        [19.3000],\n",
      "        [19.8000],\n",
      "        [22.2000],\n",
      "        [20.7000],\n",
      "        [19.5000],\n",
      "        [20.6000],\n",
      "        [19.0000],\n",
      "        [18.7000],\n",
      "        [32.7000],\n",
      "        [16.5000],\n",
      "        [23.9000],\n",
      "        [31.2000],\n",
      "        [23.1000],\n",
      "        [24.5000],\n",
      "        [26.6000],\n",
      "        [18.6000],\n",
      "        [17.8000],\n",
      "        [21.7000],\n",
      "        [22.7000],\n",
      "        [22.6000],\n",
      "        [25.0000],\n",
      "        [20.8000],\n",
      "        [27.5000],\n",
      "        [21.9000],\n",
      "        [23.1000],\n",
      "        [50.0000],\n",
      "        [50.0000],\n",
      "        [50.0000],\n",
      "        [50.0000],\n",
      "        [13.8000],\n",
      "        [13.8000],\n",
      "        [13.9000],\n",
      "        [13.3000],\n",
      "        [11.3000],\n",
      "        [12.3000],\n",
      "        [ 8.8000],\n",
      "        [10.5000],\n",
      "        [ 7.4000],\n",
      "        [11.5000],\n",
      "        [23.2000],\n",
      "        [ 9.7000],\n",
      "        [12.7000],\n",
      "        [12.5000],\n",
      "        [ 5.0000],\n",
      "        [ 5.6000],\n",
      "        [ 7.2000],\n",
      "        [ 8.3000],\n",
      "        [27.9000],\n",
      "        [17.2000],\n",
      "        [16.3000],\n",
      "        [ 7.0000],\n",
      "        [ 7.2000],\n",
      "        [10.4000],\n",
      "        [ 8.8000],\n",
      "        [ 8.4000],\n",
      "        [11.7000],\n",
      "        [ 8.3000],\n",
      "        [10.9000],\n",
      "        [11.0000],\n",
      "        [ 9.5000],\n",
      "        [14.1000],\n",
      "        [16.1000],\n",
      "        [14.3000],\n",
      "        [11.7000],\n",
      "        [ 8.7000],\n",
      "        [12.8000],\n",
      "        [10.5000],\n",
      "        [17.1000],\n",
      "        [18.4000],\n",
      "        [15.4000],\n",
      "        [10.8000],\n",
      "        [11.8000],\n",
      "        [12.6000],\n",
      "        [14.1000],\n",
      "        [15.2000],\n",
      "        [16.1000],\n",
      "        [17.8000],\n",
      "        [14.1000],\n",
      "        [13.5000],\n",
      "        [14.9000],\n",
      "        [20.0000],\n",
      "        [16.4000],\n",
      "        [17.7000],\n",
      "        [19.5000],\n",
      "        [20.2000],\n",
      "        [21.4000],\n",
      "        [19.9000],\n",
      "        [19.0000],\n",
      "        [19.1000],\n",
      "        [19.1000],\n",
      "        [20.1000],\n",
      "        [19.6000],\n",
      "        [23.2000],\n",
      "        [13.8000],\n",
      "        [16.7000],\n",
      "        [12.0000],\n",
      "        [14.6000],\n",
      "        [21.4000],\n",
      "        [23.0000],\n",
      "        [23.7000],\n",
      "        [21.8000],\n",
      "        [20.6000],\n",
      "        [19.1000],\n",
      "        [20.6000],\n",
      "        [15.2000],\n",
      "        [ 8.1000],\n",
      "        [13.6000],\n",
      "        [20.1000],\n",
      "        [21.8000],\n",
      "        [18.3000],\n",
      "        [17.5000],\n",
      "        [22.4000],\n",
      "        [20.6000],\n",
      "        [23.9000],\n",
      "        [11.9000]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "#Variable declarations\n",
    "train_data = '~/Downloads/Machine-learning/Projects/Boston-Housing/train.csv'\n",
    "train_df = pd.read_csv(train_data)\n",
    "dfh = train_df.head()\n",
    "target = train_df.iloc[:,14:15]\n",
    "inputs = train_df.iloc[:,1:14]\n",
    "\n",
    "#Test/inference dataset\n",
    "test_data = '~/Downloads/Machine-learning/Projects/Boston-Housing/test.csv'\n",
    "test_df = pd.read_csv(test_data)\n",
    "df1h = test_df.head()\n",
    "test_inputs = test_df.iloc[:,1:14]\n",
    "\n",
    "print(inputs.shape)\n",
    "print(target.shape)\n",
    "print(test_inputs.shape)\n",
    "\n",
    "#Convert df to tensors\n",
    "torch_target = torch.Tensor(target.values)\n",
    "torch_inputs = torch.Tensor(inputs.values)\n",
    "test_inputs = torch.Tensor(test_inputs.values)\n",
    "\n",
    "#Define dataset\n",
    "train_ds = TensorDataset(torch_inputs,torch_target)\n",
    "\n",
    "#Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds,batch_size,shuffle=True)\n",
    "\n",
    "loss_fn = F.mse_loss\n",
    "pred = torch.Tensor()\n",
    "#loss = loss_fn(model(torch_inputs),torch_target)\n",
    "\n",
    "#Create a function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xi,yi in train_dl:\n",
    "            pred = model(xi)\n",
    "            loss = loss_fn(pred,yi)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        if (epoch+1) % 10 ==0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "    \n",
    "    print('Trained-model loss: ',loss_fn(model(torch_inputs),torch_target))\n",
    "    preds = model(torch_inputs)\n",
    "    print(\"Predictions:\",preds)\n",
    "    print(\"Targets:\",torch_target)\n",
    "    print('')\n",
    "\n",
    "#Define model\n",
    "class NeuralN1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(13,75)\n",
    "        self.linear2 = nn.Linear(75,50)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(50,25)\n",
    "        #self.act2 = nn.ReLU()\n",
    "        self.linear4 = nn.Linear(25,12)\n",
    "        self.linear5 = nn.Linear(12,5)\n",
    "        self.linear6 = nn.Linear(5,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.act1(self.linear1(x))\n",
    "        x = self.act1(self.linear2(x))\n",
    "        #x = self.act1(x)\n",
    "        x = self.act1(self.linear3(x))\n",
    "        #x = self.act2(x)\n",
    "        x = self.act1(self.linear4(x))\n",
    "        x = self.act1(self.linear5(x))\n",
    "        x = self.linear6(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralN1()\n",
    "loss = loss_fn(model(torch_inputs),torch_target)\n",
    "print('Initial loss:', loss)\n",
    "print('')\n",
    "opt1 = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "opt2 = torch.optim.Adagrad(model.parameters(), lr = 1e-5)\n",
    "\n",
    "fit(700,model,loss_fn,opt1)\n",
    "pred = model(torch_inputs)\n",
    "#print(pred)\n",
    "#fit(100,model,loss_fn,opt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
