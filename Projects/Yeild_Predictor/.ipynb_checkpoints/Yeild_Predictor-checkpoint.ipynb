{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training loss: tensor(14327.4521, grad_fn=<MseLossBackward>)\n",
      "Final Training loss: tensor(47.2112, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#3 copies of data in order to simulate real world cases of large datasets\n",
    "inputs = np.array([[73,67,43],[91,88,64],[87,134,58],[102,43,37],[69,96,70],[73,67,43],[91,88,64],[87,134,58],[102,43,37],[69,96,70],[73,67,43],[91,88,64],[87,134,58],[102,43,37],[69,96,70]],dtype='float32')\n",
    "targets = np.array([[56,70],[81,101],[119,133],[22,37],[103,119],[56,70],[81,101],[119,133],[22,37],[103,119],[56,70],[81,101],[119,133],[22,37],[103,119]], dtype='float32')\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "\n",
    "batch_size=5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "next(iter(train_dl))\n",
    "                    \n",
    "model = nn.Linear(3,2)\n",
    "opt = torch.optim.SGD(model.parameters(), lr =1e-5)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "loss_fn = F.mse_loss\n",
    "loss = loss_fn(model(inputs),targets)\n",
    "print('Initial Training loss:',loss)\n",
    "\n",
    "#Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            #Generate predictions\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            #Perform Gradient Descent\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    print('Final Training loss:',loss_fn(model(inputs),targets))\n",
    "    \n",
    "fit(100,model,loss_fn,opt)\n",
    "preds = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training loss: tensor(23.3978, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(3,3)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(3,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "model1 = SimpleNet()\n",
    "opt = torch.optim.SGD(model1.parameters(), lr =1e-5)\n",
    "loss_fn = F.mse_loss\n",
    "fit(100,model,loss_fn,opt)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
